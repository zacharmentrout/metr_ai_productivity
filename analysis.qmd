---
title: "Bayesian Reanalysis of METR AI Developer Productivity Study"
format:
  html:
    embed-resources: true
---

```{r}
#| label: setup
#| message: false

util <- new.env()
source("mcmc_visualization_tools/r/mcmc_analysis_tools_rstan.R", local = util)
source("mcmc_visualization_tools/r/mcmc_visualization_tools.R", local = util)
source("functions.R", local=util)

library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

# Color for prior overlay
c_light_teal <- "#6BAED6"

```

# Exploratory Data Analysis

```{r}
#| label: load-data

dat <- read.csv("data/data_complete.csv")

# Compute total implementation time (minutes)
dat$total_time <- dat$initial_implementation_time + dat$post_review_implementation_time

# Forecast time (minutes)
dat$forecast <- dat$predicted_time_no_ai

# Recode treatment: 1 = AI access, 0 = AI restricted
dat$ai_access <- 1 - dat$ai_treatment

dat$dev_num <- as.integer(factor(dat$dev_id))

```

```{r}
#| label: fig-completion-times
#| fig-cap: "Distribution of observed completion times (minutes)"

util$plot_line_hist(dat$total_time[!is.na(dat$total_time)],
                    0, 1500, 50,
                    xlab = "Completion time (minutes)")
```

```{r}
#| label: fig-forecast-times
#| fig-cap: "Distribution of forecast times (minutes)"

util$plot_line_hist(dat$forecast,
                    0, 800, 25,
                    xlab = "Forecast time (minutes)")
```

Mean developer outcomes

```{r}

mean_total_time_developer <-
  sapply(1:max(dat$dev_num),
         function(c) mean(dat$total_time[dat$dev_num == c & !is.na(dat$total_time)]))

util$plot_line_hist(mean_total_time_developer)
```

```{r}
#| label: data-summary

cat("N (complete cases):", sum(!is.na(dat$total_time)), "\n")
cat("N (missing):", sum(is.na(dat$total_time)), "\n")
cat("\n")

cat("total_time (minutes):\n")
cat("  median:", median(dat$total_time, na.rm = TRUE), "\n")
cat("  mean:", round(mean(dat$total_time, na.rm = TRUE), 1), "\n")
cat("  sd:", round(sd(dat$total_time, na.rm = TRUE), 1), "\n")
cat("  range:", range(dat$total_time, na.rm = TRUE), "\n")

cat("\nforecast (minutes):\n")
cat("  median:", median(dat$forecast), "\n")
cat("  mean:", round(mean(dat$forecast), 1), "\n")
cat("  sd:", round(sd(dat$forecast), 1), "\n")
cat("  range:", range(dat$forecast), "\n")

cat("\nai_access:\n")
cat("  n(AI allowed):", sum(dat$ai_access == 1), "\n")
cat("  n(AI restricted):", sum(dat$ai_access == 0), "\n")
```

# Model 1: Bayesian Regression

## Model Structure

We model completion time with a lognormal likelihood, regressing on treatment and forecast:

$$y_i \sim \text{Lognormal}(\mu_i, \sigma)$$ $$\mu_i = \alpha + \beta_{\text{trt}} \cdot \text{ai_access}_i + \beta_{\text{forecast}} \cdot \log(\text{forecast}_i / 90)$$

The baseline forecast is set to 90 minutes (approximately the median). This means:

-   $\alpha$ = expected log(completion time) when forecast = 90 min and AI restricted
-   $\exp(\alpha)$ = median completion time at baseline
-   $\beta_{\text{trt}}$ = effect of AI access on log completion time
-   $\beta_{\text{forecast}}$ = elasticity (if forecast doubles, completion time multiplies by $2^{\beta_{\text{forecast}}}$)

## Prior Development

We calibrate priors using domain expertise about plausible parameter ranges. For each parameter, we identify extremity thresholds and set the prior SD so that 1% of probability falls beyond each threshold.

**Intercept (**$\alpha$): At baseline (forecast = 90 min, AI restricted), median completion time plausibly ranges from 45 to 180 minutes. On log scale: $\log(45) \approx 3.8$ to $\log(180) \approx 5.2$, centered at $\log(90) \approx 4.5$.

$$\alpha \sim \text{Normal}(\log(90), 0.30)$$

**Treatment effect (**$\beta_{\text{trt}}$): A 95% reduction (log change of -3) or 5x increase (log change of +1.6) from AI access would be implausible.

$$\beta_{\text{trt}} \sim \text{Normal}(0, 0.7)$$

**Forecast elasticity (**$\beta_{\text{forecast}}$): We expect forecasts to be predictive. An elasticity between 0.25 and 1.75 is plausible; values outside this range are unlikely.

$$\beta_{\text{forecast}} \sim \text{Normal}(1, 0.32)$$

**Residual dispersion (**$\sigma$): Starting with $\sigma = 1$ and tuning based on prior predictive checks. Goal: 99% of simulated completion times between 10 min and 24 hours.

## Prior Predictive Check

We simulate data from the prior to verify our priors produce plausible datasets before seeing any real data.

```{r}
#| label: model1-prior-data

complete_idx <- !is.na(dat$total_time)

stan_data <- list(
  N = sum(complete_idx),
  forecast = dat$forecast[complete_idx],
  ai_access = dat$ai_access[complete_idx],
  x0 = 90
)
```

```{r}
#| label: model1-prior-fit

fit_prior <- stan(
  file = "stan_programs/model1_prior.stan",
  data = stan_data,
  algorithm = "Fixed_param",
  iter = 1000,
  chains = 1,
  seed = 1234
)

samples_prior <- util$extract_expectand_vals(fit_prior)
```

### Prior on $\alpha$ (log baseline median)

Dashed lines show the extremity thresholds: log(45) and log(180) minutes.

```{r}
#| label: fig-prior-alpha
#| fig-cap: "Prior on alpha: log(median completion time) at baseline"

util$plot_line_hist(samples_prior$alpha, 3.5, 5.5, 0.1,
                    xlab = "alpha (log minutes)")
abline(v = log(45), lty = 2, lwd = 2)   # Lower threshold: 45 min
abline(v = log(180), lty = 2, lwd = 2)  # Upper threshold: 180 min
```

### Prior on $\mu$ (log median completion time)

Distribution of $\mu = \alpha + \beta_{\text{trt}} \cdot \text{ai_access} + \beta_{\text{forecast}} \cdot \log(\text{forecast}/90)$ across all observations and prior draws. Dashed lines show log(10 min) and log(24 hours) — the target range for plausible completion times.

```{r}
#| label: fig-prior-mu
#| fig-cap: "Prior predictive: log median completion time (with treatment effect)"

util$plot_hist_quantiles(samples_prior, 'mu', 0, 8, 0.25,
                         xlab = "mu (log minutes)")
abline(v = log(10), lty = 2, lwd = 2)    # 10 min
abline(v = log(1440), lty = 2, lwd = 2)  # 24 hours
```

```{r}
#| label: fig-prior-mu-no-trt
#| fig-cap: "Prior predictive: log median completion time (no treatment effect)"

util$plot_hist_quantiles(samples_prior, 'mu_no_trt', 0, 8, 0.25,
                         xlab = "mu (log minutes)")
abline(v = log(10), lty = 2, lwd = 2)    # 10 min
abline(v = log(1440), lty = 2, lwd = 2)  # 24 hours
```

### Prior predictive on $y$ (completion time in minutes)

The lognormal model adds dispersion $\sigma$ around the median. Dashed lines show the target range: 10 min to 24 hours (1440 min).

```{r}
#| label: fig-prior-y
#| fig-cap: "Prior predictive: completion time (minutes)"

util$plot_hist_quantiles(samples_prior, 'y_sim', 0, 1500, 25,
                         xlab = "Completion time (minutes)")
abline(v = 10, lty = 2, lwd = 2)    # 10 min
abline(v = 1440, lty = 2, lwd = 2)  # 24 hours
```

```{r}
#| label: fig-prior-y-no-trt
#| fig-cap: "Prior predictive: completion time without treatment (minutes)"

util$plot_hist_quantiles(samples_prior, 'y_sim_no_trt', 0, 1500, 25,
                         xlab = "Completion time (minutes)")
abline(v = 10, lty = 2, lwd = 2)    # 10 min
abline(v = 1440, lty = 2, lwd = 2)  # 24 hours
```

### Prior predictive at baseline (forecast = 90 min, no treatment)

Dashed lines show the alpha extremity thresholds on the original scale: 45 and 180 minutes.

```{r}
#| label: fig-prior-y-baseline
#| fig-cap: "Prior predictive: completion time at baseline"

util$plot_line_hist(samples_prior$y_sim_baseline, 0, 600, 20,
                    xlab = "Completion time (minutes)")
abline(v = 45, lty = 2, lwd = 2)   # Lower threshold
abline(v = 180, lty = 2, lwd = 2)  # Upper threshold
```

### Prior predictive on log scale

Dashed lines show log(10 min) and log(24 hours).

```{r}
#| label: fig-prior-log-y
#| fig-cap: "Prior predictive: log completion time"

util$plot_hist_quantiles(samples_prior, 'log_y_sim', 0, 10, 0.25,
                         xlab = "log(completion time)")
abline(v = log(10), lty = 2, lwd = 2)    # 10 min
abline(v = log(1440), lty = 2, lwd = 2)  # 24 hours
```

### Prior on treatment effect (percentage lift)

Since $\beta_{\text{trt}}$ is the treatment effect on the log scale, the percentage change in completion time from AI access is $(e^{\beta_{\text{trt}}} - 1) \times 100\%$. Negative values indicate speedup; positive values indicate slowdown. Dashed lines show the extremity thresholds: 95% reduction (-95%) and 5x increase (+400%).

```{r}
#| label: fig-prior-ate-pct
#| fig-cap: "Prior on treatment effect: percentage change in completion time"

pct_lift <- (exp(samples_prior$beta_trt) - 1) * 100
util$plot_line_hist(pct_lift, -100, 500, 20,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)          # No effect
abline(v = -95, lty = 2, lwd = 2)        # 95% reduction (implausible)
abline(v = 400, lty = 2, lwd = 2)        # 5x increase (implausible)
```

## Model Fitting

```{r}
#| label: model1-fit-data

complete_idx <- !is.na(dat$total_time)

stan_data_fit <- list(
  N = sum(complete_idx),
  dev_nums = dat$dev_num[complete_idx],
  N_developers = length(unique(dat$dev_num[complete_idx])),
  y = dat$total_time[complete_idx],
  forecast = dat$forecast[complete_idx],
  ai_access = dat$ai_access[complete_idx],
  
  x0 = 90
)
```

```{r}
#| label: model1-fit

fit <- stan(
  file = "stan_programs/model1.stan",
  data = stan_data_fit,
  seed = 8877273,
  refresh = 100
)
```

```{r}
#| label: model1-diagnostics

util$check_all_hmc_diagnostics(util$extract_hmc_diagnostics(fit))
samples <- util$extract_expectand_vals(fit)
base_samples <- util$filter_expectands(samples, c('beta_trt', 'alpha', 'beta_forecast', 'sigma'))
util$check_all_expectand_diagnostics(base_samples)

```

## Posterior Retrodictive Checks

### Log completion time

Comparing posterior predictive distribution of log completion times against observed data (black histogram).

```{r}
#| label: fig-retro-log-y
#| fig-cap: "Posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_fit$y),
                         xlab = "log(completion time)")
```

### Treatment effect (percentage lift)

Posterior distribution of the treatment effect as percentage change in completion time. The dashed line shows the observed difference in median completion times between AI-allowed and AI-restricted groups.

```{r}
#| label: fig-retro-ate-pct
#| fig-cap: "Posterior: treatment effect (% change in completion time)"

# Observed percentage difference in medians
y_ai <- dat$total_time[complete_idx & dat$ai_access == 1]
y_no_ai <- dat$total_time[complete_idx & dat$ai_access == 0]
observed_pct_diff <- (median(y_ai) / median(y_no_ai) - 1) * 100

util$plot_line_hist(samples$pct_lift, -80, 80, 5,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)
abline(v = observed_pct_diff, lty = 2, lwd = 2)
```

### Parameter summaries

```{r}
#| label: model1-summary

print(fit, pars = c("alpha", "beta_trt", "beta_forecast", "sigma", "pct_lift"))
```

### Conditional mean by task exposure

```{r}
#| label: fig-retro-cond-exposure
#| fig-cap: "Posterior retrodictive: completion time by prior task exposure"

# Get complete case data (what was modeled)
dat_complete <- dat[complete_idx, ]

# Find which complete cases have non-NA exposure
has_exposure <- !is.na(dat_complete$prior_task_exposure_1_to_5)

# Indices into y_rep (1:N for complete cases)
n_cond_mean <- which(has_exposure)

# Covariate values and observed outcomes for these observations
obs_xs <- dat_complete$prior_task_exposure_1_to_5[has_exposure]
obs_ys <- dat_complete$total_time[has_exposure]

# y_rep names for these observations
names <- paste0('y_pred[', n_cond_mean, ']')

util$plot_conditional_mean_quantiles(samples, names, obs_xs,
                                     0.5, 5.5, 1, obs_ys,
                                     xlab = "Prior task exposure (1-5)",
                                     ylab = "Completion time (minutes)")
```

Conditional Means by Resource Needs

```{r}
#| label: fig-retro-cond-exposure
#| fig-cap: "Posterior retrodictive: completion time by resource needs"

# Get complete case data (what was modeled)
dat_complete <- dat[complete_idx, ]

# Find which complete cases have non-NA exposure
has_resource_needs <- !is.na(dat_complete$external_resource_needs_1_to_3)

# Indices into y_rep (1:N for complete cases)
n_cond_mean <- which(has_resource_needs)

# Covariate values and observed outcomes for these observations
obs_xs <- dat_complete$external_resource_needs_1_to_3[has_resource_needs]
obs_xs[obs_xs == 5] <- 3
obs_ys <- dat_complete$total_time[has_resource_needs]

# y_rep names for these observations
names <- paste0('y_pred[', n_cond_mean, ']')

util$plot_conditional_mean_quantiles(samples, names, obs_xs,
                                     0.5, 3.5, 1, obs_ys,
                                     xlab = "Resource Needs (1 to 3)",
                                     ylab = "Completion time (minutes)")
```

Conditional means by forecast

```{r}
#| label: fig-retro-cond-exposure
#| fig-cap: "Posterior retrodictive: completion time by forecast"

# Get complete case data (what was modeled)
dat_complete <- dat[complete_idx, ]

# Find which complete cases have non-NA forecast
has_forecast <- !is.na(dat_complete$forecast)

# Indices into y_rep (1:N for complete cases)
n_cond_mean <- which(has_forecast)

# Covariate values and observed outcomes for these observations
obs_xs <- dat_complete$forecast[has_forecast]
obs_ys <- dat_complete$total_time[has_forecast]

# y_rep names for these observations
names <- paste0('y_pred[', n_cond_mean, ']')

util$plot_conditional_mean_quantiles(samples, names, obs_xs,bin_min=0, bin_max=400,bin_delta = 50,
                                    obs_ys,
                                     xlab = "Forecast",
                                     ylab = "Completion time (minutes)")
```

```{r}
pred_names <- paste0('mean_outcome_dev_pred[',1:stan_data_fit$N_developers,']')
util$plot_hist_quantiles(samples[pred_names], 'mean_outcome_dev_pred',
                         #0, 3, 0.25,
                         baseline_values=mean_total_time_developer,
                         xlab="Developer-wise Average Total Time")

```

Next we'll model the ability of each developer which helps generate resource needs, prior task exposure, and completion time forecasts.

# Model 2: Latent Task Burden

## Model Structure

We introduce a latent "task burden" variable that generates both forecasts and completion times:

$$\text{task_burden}_i \sim \text{Normal}(0, \sigma_b)$$ $$\text{forecast}_i \sim \text{Lognormal}(\alpha_f + \text{task_burden}_i, \sigma_f)$$ $$y_i \sim \text{Lognormal}(\alpha_t + \beta_{\text{trt}} \cdot \text{ai_access}_i + \beta_{\text{burden}} \cdot \text{task_burden}_i, \sigma_t)$$

This treats forecasts as outcomes of latent structure rather than inputs.

### Marginalized Likelihood

Fitting N latent task_burden parameters creates funnel geometry that HMC struggles to navigate. Since task_burden is normally distributed and appears linearly in both log-likelihoods, we can marginalize it out analytically.

On the log scale, writing $f_i = \log(\text{forecast}_i)$ and $t_i = \log(y_i)$:

$$f_i \mid \text{task_burden}_i \sim \text{Normal}(\alpha_f + \text{task_burden}_i, \sigma_f)$$ $$t_i \mid \text{task_burden}_i \sim \text{Normal}(\alpha_t + \beta_{\text{trt}} \cdot \text{ai_access}_i + \beta_{\text{burden}} \cdot \text{task_burden}_i, \sigma_t)$$

The marginal means (integrating out task_burden):

$$\mathbb{E}[f_i] = \alpha_f$$ $$\mathbb{E}[t_i] = \alpha_t + \beta_{\text{trt}} \cdot \text{ai_access}_i$$

The marginal variances decompose into latent variance plus noise:

$$\text{Var}(f_i) = \sigma_b^2 + \sigma_f^2$$ $$\text{Var}(t_i) = \beta_{\text{burden}}^2 \sigma_b^2 + \sigma_t^2$$

The covariance arises from the shared latent task_burden:

$$\text{Cov}(f_i, t_i) = \beta_{\text{burden}} \sigma_b^2$$

This gives a bivariate normal likelihood:

$$\begin{pmatrix} f_i \\ t_i \end{pmatrix} \sim \text{Normal}\left( \begin{pmatrix} \alpha_f \\ \alpha_t + \beta_{\text{trt}} \cdot \text{ai_access}_i \end{pmatrix}, \begin{pmatrix} \sigma_b^2 + \sigma_f^2 & \beta_{\text{burden}} \sigma_b^2 \\ \beta_{\text{burden}} \sigma_b^2 & \beta_{\text{burden}}^2 \sigma_b^2 + \sigma_t^2 \end{pmatrix} \right)$$

The induced correlation between log-forecast and log-completion time is:

$$\rho = \frac{\beta_{\text{burden}} \sigma_b^2}{\sqrt{(\sigma_b^2 + \sigma_f^2)(\beta_{\text{burden}}^2 \sigma_b^2 + \sigma_t^2)}}$$

## Prior Development

| Parameter | Prior | Interpretation |
|----|----|----|
| σ_b | Half-Normal(0, 0.39) | Task burden spread; 99% \< 1 |
| σ_f | Half-Normal(0, 0.39) | Forecast noise after burden; 99% \< 1 |
| σ_t | Half-Normal(0, 0.25) | Completion noise after burden; 99% \< 0.64 |
| α_f | Normal(log(90), 0.30) | Log median forecast at avg burden; 45-180 min |
| α_t | Normal(log(90), 0.40) | Log median completion at avg burden; 35-230 min |
| β_burden | Normal(1, 0.32) | Burden → completion; 0.25-1.75 |
| β_trt | Normal(0, 0.7) | Treatment effect (same as Model 1) |

## Prior Predictive Check

```{r}
#| label: model2-prior-data

stan_data_m2 <- list(
  N = sum(complete_idx),
  ai_access = dat$ai_access[complete_idx]
)
```

```{r}
#| label: model2-prior-fit

fit_prior_m2 <- stan(
  file = "stan_programs/model2_prior.stan",
  data = stan_data_m2,
  algorithm = "Fixed_param",
  iter = 1000,
  chains = 1,
  seed = 1234
)

samples_prior_m2 <- util$extract_expectand_vals(fit_prior_m2)
```

### Prior on simulated forecasts

Dashed lines show 10 min and 24 hours (1440 min).

```{r}
#| label: fig-m2-prior-forecast
#| fig-cap: "Model 2 prior predictive: forecast times (minutes)"

util$plot_hist_quantiles(samples_prior_m2, 'forecast_sim', 0, 1500, 25,
                         xlab = "Forecast time (minutes)")
abline(v = 10, lty = 2, lwd = 2)
abline(v = 1440, lty = 2, lwd = 2)
```

```{r}
#| label: fig-m2-prior-log-forecast
#| fig-cap: "Model 2 prior predictive: log forecast times"

util$plot_hist_quantiles(samples_prior_m2, 'log_forecast_sim', 0, 10, 0.25,
                         xlab = "log(forecast time)")
abline(v = log(10), lty = 2, lwd = 2)
abline(v = log(1440), lty = 2, lwd = 2)
```

### Prior on simulated completion times

```{r}
#| label: fig-m2-prior-y
#| fig-cap: "Model 2 prior predictive: completion time (minutes)"

util$plot_hist_quantiles(samples_prior_m2, 'y_sim', 0, 1500, 25,
                         xlab = "Completion time (minutes)")
abline(v = 10, lty = 2, lwd = 2)
abline(v = 1440, lty = 2, lwd = 2)
```

```{r}
#| label: fig-m2-prior-log-y
#| fig-cap: "Model 2 prior predictive: log completion time"

util$plot_hist_quantiles(samples_prior_m2, 'log_y_sim', 0, 10, 0.25,
                         xlab = "log(completion time)")
abline(v = log(10), lty = 2, lwd = 2)
abline(v = log(1440), lty = 2, lwd = 2)
```

### Prior on treatment effect (percentage lift)

```{r}
#| label: fig-m2-prior-ate-pct
#| fig-cap: "Model 2 prior: treatment effect (% change)"

pct_lift_m2 <- (exp(samples_prior_m2$beta_trt) - 1) * 100
util$plot_line_hist(pct_lift_m2, -100, 500, 20,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)
abline(v = -95, lty = 2, lwd = 2)
abline(v = 400, lty = 2, lwd = 2)
```

## Model Fitting

The latent task burden model has N latent parameters (one per observation), which creates funnel geometry that HMC struggles to navigate. We marginalize out the latent task_burden analytically, yielding a bivariate normal likelihood for (log_forecast, log_y) with correlation induced by the shared latent structure.

```{r}
#| label: model2-fit-data

stan_data_m2_fit <- list(
  N = sum(complete_idx),
  y = dat$total_time[complete_idx],
  forecast = dat$forecast[complete_idx],
  ai_access = dat$ai_access[complete_idx]
)
```

```{r}
#| label: model2-fit

fit_m2 <- stan(
  file = "stan_programs/model2_marginalized.stan",
  data = stan_data_m2_fit,
  seed = 5678,
  refresh = 100,
  control = list(adapt_delta=0.95)
)
```

```{r}
#| label: model2-diagnostics

util$check_all_hmc_diagnostics(util$extract_hmc_diagnostics(fit_m2))
samples_m2 <- util$extract_expectand_vals(fit_m2)
base_samples_m2 <- util$filter_expectands(samples_m2, c('beta_trt', 'alpha_f', 'alpha_t', 'beta_burden', 'sigma_b', 'sigma_f', 'sigma_t'))
util$check_all_expectand_diagnostics(base_samples_m2)
```

## Posterior Retrodictive Checks

### Log completion time

```{r}
#| label: fig-m2-retro-log-y
#| fig-cap: "Model 2 posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples_m2, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m2_fit$y),
                         xlab = "log(completion time)")
```

### Log forecast time

```{r}
#| label: fig-m2-retro-log-forecast
#| fig-cap: "Model 2 posterior retrodictive: log forecast time"

util$plot_hist_quantiles(samples_m2, 'log_forecast_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m2_fit$forecast),
                         xlab = "log(forecast time)")
```

### Treatment effect (percentage lift)

```{r}
#| label: fig-m2-retro-ate-pct
#| fig-cap: "Model 2 posterior: treatment effect (% change)"

# Observed percentage difference in medians
y_ai <- dat$total_time[complete_idx & dat$ai_access == 1]
y_no_ai <- dat$total_time[complete_idx & dat$ai_access == 0]
observed_pct_diff <- (median(y_ai) / median(y_no_ai) - 1) * 100

util$plot_line_hist(samples_m2$pct_lift, -80, 80, 5,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)
abline(v = observed_pct_diff, lty = 2, lwd = 2)
```

### Posterior on induced correlation

The correlation between log(forecast) and log(completion time) induced by the shared task burden:

```{r}
#| label: fig-m2-post-rho
#| fig-cap: "Model 2 posterior: induced correlation between forecast and completion time"

util$plot_line_hist(samples_m2$rho, 0, 1, 0.05,
                    xlab = "Correlation (rho)")
```

### Parameter summaries

```{r}
#| label: model2-summary

print(fit_m2, pars = c("alpha_f", "alpha_t", "beta_burden", "beta_trt",
                        "sigma_b", "sigma_f", "sigma_t", "pct_lift",
                        "var_f", "var_t", "rho"))
```

### Compare Model 1 vs Model 2 treatment effects

```{r}
#| label: fig-compare-ate
#| fig-cap: "Comparison: treatment effect estimates"

# Model 1 posterior
pct_lift_m1 <- samples$pct_lift

# Model 2 posterior
pct_lift_m2_post <- samples_m2$pct_lift

# Plot both
util$plot_line_hist(pct_lift_m1, -80, 80, 5,
                    xlab = "Treatment effect (% change)",col = 'blue',prob = T)
util$plot_line_hist(pct_lift_m2_post, -80, 80, 5, add = TRUE,
                    col = 'darkgreen', prob=T)
legend("topright", c("Model 1", "Model 2"),
       fill = c('blue', 'darkgreen'))
```

# Model 3: Negative Binomial Forecasts with Latent Task Burden

## Model Structure

We replace the lognormal likelihood for forecasts with a Negative Binomial likelihood on the scaled values. Since forecasts come in increments of 5 minutes, we model:

```         
forecast = 5 * Z,  where Z ~ NegBinomial2(mu, phi)
log(mu) = alpha_f + task_burden
```

We parameterize overdispersion as `kappa = 1/phi`, so:

```         
Var(Z) = mu + mu^2 * kappa
```

-   kappa = 0: Poisson (no overdispersion)
-   kappa \> 0: overdispersed (larger kappa = more variance)

The full generative structure:

```         
task_burden[n] ~ Normal(0, sigma_b)
forecast_int[n] ~ NegBinomial2(exp(alpha_f + task_burden[n]), 1/kappa)
y[n] ~ Lognormal(alpha_t + beta_trt * ai_access[n] + beta_burden * task_burden[n], sigma_t)
```

where `forecast_int = round(forecast / 5)`.

This model is *not* marginalized — we estimate task_burden explicitly. The discrete likelihood may provide better geometry than the continuous lognormal.

## Prior Development

| Parameter | Prior | Interpretation |
|----|----|----|
| sigma_b | Half-Normal(0, 0.39) | Task burden spread; 99% \< 1 |
| sigma_t | Half-Normal(0, 0.25) | Completion noise; 99% \< 0.64 |
| kappa | Half-Normal(0, 0.10) | Overdispersion; 99% \< 0.25; SD(forecast) \< 50 min |
| alpha_f | Normal(log(18), 0.30) | Log expected forecast/5 at avg burden; 9-36 |
| alpha_t | Normal(log(90), 0.40) | Log median completion at avg burden |
| beta_burden | Normal(1, 0.32) | Burden effect on completion; 0.25-1.75 |
| beta_trt | Normal(0, 0.7) | Treatment effect |

## Model Fitting

```{r}
#| label: model3-fit

fit_m3 <- stan(
  file = "stan_programs/model3.stan",
  data = stan_data_m2_fit,
  seed = 91011,
  refresh = 200,
  control = list(adapt_delta=0.9)
)
```

```{r}
#| label: model3-diagnostics

util$check_all_hmc_diagnostics(util$extract_hmc_diagnostics(fit_m3))
samples_m3 <- util$extract_expectand_vals(fit_m3)
base_samples_m3 <- util$filter_expectands(samples_m3,
  c('beta_trt', 'alpha_f', 'alpha_t', 'beta_burden', 'sigma_b', 'sigma_t', 'kappa', 'phi'))
util$check_all_expectand_diagnostics(base_samples_m3)
```

## Posterior Retrodictive Checks

### Log completion time

```{r}
#| label: fig-m3-retro-log-y
#| fig-cap: "Model 3 posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples_m3, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m2_fit$y),
                         xlab = "log(completion time)")
```

### Forecast (on original scale)

```{r}
#| label: fig-m3-retro-forecast
#| fig-cap: "Model 3 posterior retrodictive: forecast time"

util$plot_hist_quantiles(samples_m3, 'forecast_pred', 0, 800, 25,
                         baseline_values = stan_data_m2_fit$forecast,
                         xlab = "Forecast time (minutes)")
```

### Treatment effect

```{r}
#| label: fig-m3-retro-ate-pct
#| fig-cap: "Model 3 posterior: treatment effect (% change)"

y_ai <- dat$total_time[complete_idx & dat$ai_access == 1]
y_no_ai <- dat$total_time[complete_idx & dat$ai_access == 0]
observed_pct_diff <- (median(y_ai) / median(y_no_ai) - 1) * 100

util$plot_line_hist(samples_m3$pct_lift, -80, 80, 5,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)
abline(v = observed_pct_diff, lty = 2, lwd = 2)
```

### Parameter summaries

```{r}
#| label: model3-summary

print(fit_m3, pars = c("alpha_f", "alpha_t", "beta_burden", "beta_trt",
                        "sigma_b", "sigma_t", "kappa", "phi", "pct_lift"))
```

### Prior vs Posterior Comparisons

```{r}
#| label: fig-m3-prior-post-sigma-b
#| fig-cap: "Model 3: Prior (teal) vs Posterior for sigma_b"

util$plot_expectand_pushforward(samples_m3[["sigma_b"]], 25,
                                display_name = "sigma_b", flim = c(0, 1.5))
xs <- seq(0, 1.5, 0.01)
ys <- 2 * dnorm(xs, 0, 0.39)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m3-prior-post-sigma-t
#| fig-cap: "Model 3: Prior (teal) vs Posterior for sigma_t"

util$plot_expectand_pushforward(samples_m3[["sigma_t"]], 25,
                                display_name = "sigma_t", flim = c(0, 0.8))
xs <- seq(0, 0.8, 0.01)
ys <- 2 * dnorm(xs, 0, 0.25)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m3-prior-post-kappa
#| fig-cap: "Model 3: Prior (teal) vs Posterior for kappa (overdispersion)"

util$plot_expectand_pushforward(samples_m3[["kappa"]], 25,
                                display_name = "kappa", flim = c(0, 0.5))
xs <- seq(0, 0.5, 0.005)
ys <- 2 * dnorm(xs, 0, 0.10)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m3-prior-post-alpha-f
#| fig-cap: "Model 3: Prior (teal) vs Posterior for alpha_f"

util$plot_expectand_pushforward(samples_m3[["alpha_f"]], 25,
                                display_name = "alpha_f", flim = c(1.5, 4))
xs <- seq(1.5, 4, 0.01)
ys <- dnorm(xs, log(17), 0.30)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m3-prior-post-alpha-t
#| fig-cap: "Model 3: Prior (teal) vs Posterior for alpha_t"

util$plot_expectand_pushforward(samples_m3[["alpha_t"]], 25,
                                display_name = "alpha_t", flim = c(3, 6))
xs <- seq(3, 6, 0.01)
ys <- dnorm(xs, log(90), 0.40)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m3-prior-post-beta-burden
#| fig-cap: "Model 3: Prior (teal) vs Posterior for beta_burden"

util$plot_expectand_pushforward(samples_m3[["beta_burden"]], 25,
                                display_name = "beta_burden", flim = c(0, 2.5))
xs <- seq(0, 2.5, 0.01)
ys <- dnorm(xs, 1, 0.32)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m3-prior-post-beta-trt
#| fig-cap: "Model 3: Prior (teal) vs Posterior for beta_trt"

util$plot_expectand_pushforward(samples_m3[["beta_trt"]], 25,
                                display_name = "beta_trt", flim = c(-2, 2))
xs <- seq(-2, 2, 0.01)
ys <- dnorm(xs, 0, 0.7)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

### Compare treatment effects across models

```{r}
#| label: fig-compare-ate-all
#| fig-cap: "Comparison: treatment effect estimates across all models"

util$plot_line_hist(samples$pct_lift, -80, 80, 5,
                    xlab = "Treatment effect (% change)", col = 'blue', prob = TRUE)
util$plot_line_hist(samples_m2$pct_lift, -80, 80, 5, add = TRUE,
                    col = 'darkgreen', prob = TRUE)
util$plot_line_hist(samples_m3$pct_lift, -80, 80, 5, add = TRUE,
                    col = 'darkorange', prob = TRUE)
legend("topright", c("Model 1", "Model 2 (marginalized)", "Model 3 (Poisson)"),
       fill = c('blue', 'darkgreen', 'darkorange'))
```

# Appendix: Investigating Funnel Geometry in Non-Marginalized Model 2

The non-marginalized Model 2 (with explicit task_burden parameters) exhibits severe sampling issues. With very low E-FMI (\< 0.2) but few divergences, the problem is not that the sampler is crashing — it's that the sampler is moving *extremely slowly* through the funnel geometry. HMC adapts by taking tiny steps to avoid diverging, but this results in poor exploration (low ESS) and chains that don't mix.

## Fit Non-Marginalized Model

```{r}
#| label: model2-nonmarg-fit

fit_m2_nonmarg <- stan(
  file = "stan_programs/model2.stan",
  data = stan_data_m2_fit,
  seed = 5678,
  refresh = 0
)
```

```{r}
#| label: model2-nonmarg-diagnostics

diagnostics_m2_nonmarg <- util$extract_hmc_diagnostics(fit_m2_nonmarg)
util$check_all_hmc_diagnostics(diagnostics_m2_nonmarg)

samples_m2_nonmarg <- util$extract_expectand_vals(fit_m2_nonmarg)
```

## Understanding Low E-FMI

E-FMI (Energy Fraction of Missing Information) measures how effectively momentum helps explore the posterior. When E-FMI is very low:

-   The sampler's momentum isn't carrying it efficiently through parameter space
-   Chains diffuse slowly rather than making large jumps
-   Different chains may get stuck in different regions
-   ESS will be low even without divergences

This happens in funnel geometry because:

1.  The narrow neck (small σ_b) requires tiny step sizes
2.  The wide mouth (large σ_b) could use larger steps
3.  HMC uses a single adapted step size — too large for the neck, too small for the mouth
4.  The sampler survives but crawls through the space

## Visualizing Poor Mixing

We use `plot_pairs_by_chain` to see how each chain explores the (σ_b, task_burden) space over iterations. Colors indicate iteration order (light = early, dark = late). Well-mixing chains would show all colors covering the same region; poorly-mixing chains show clusters or slow drift.

```{r}
#| label: fig-pairs-chain-sigma-burden
#| fig-cap: "Pairs by chain: sigma_b vs task_burden[1]. Color = iteration (light=early, dark=late)"
#| fig-width: 10
#| fig-height: 8

util$plot_pairs_by_chain(
  samples_m2_nonmarg[["sigma_b"]], "sigma_b",
  samples_m2_nonmarg[["task_burden[1]"]], "task_burden[1]"
)
```

If chains are mixing well, all four panels should show similar coverage with colors interspersed. If chains are stuck or slowly drifting, you'll see:

-   Different chains in different regions
-   Color gradients showing slow drift rather than rapid mixing
-   Clusters of similar-colored points

```{r}
#| label: fig-pairs-chain-sigmas
#| fig-cap: "Pairs by chain: sigma_b vs sigma_f"
#| fig-width: 10
#| fig-height: 8

util$plot_pairs_by_chain(
  samples_m2_nonmarg[["sigma_b"]], "sigma_b",
  samples_m2_nonmarg[["sigma_f"]], "sigma_f"
)
```

## The Funnel Geometry

Even without many divergences, we can visualize the funnel by plotting σ_b against task_burden. The characteristic shape: when σ_b is small, task_burden is constrained near zero; when σ_b is large, task_burden spreads out.

```{r}
#| label: fig-funnel-sigma-b
#| fig-cap: "Funnel geometry: log(sigma_b) vs selected task_burden parameters"
#| fig-width: 10
#| fig-height: 8

util$plot_div_pairs(
  x_names = c("sigma_b"),
  y_names = c("task_burden[1]", "task_burden[10]", "task_burden[20]",
              "task_burden[50]", "task_burden[100]", "task_burden[150]"),
  expectand_vals_list = samples_m2_nonmarg,
  diagnostics = diagnostics_m2_nonmarg,
  transforms = list("sigma_b" = 1),
  plot_mode = 0
)
```

## Trajectory Lengths

When the sampler struggles with geometry, it often shows unusual trajectory length patterns. Very short trajectories indicate the sampler is U-turning quickly (possibly stuck); very long trajectories may indicate difficulty finding the right direction.

```{r}
#| label: fig-leapfrogs
#| fig-cap: "Distribution of numerical trajectory lengths by chain"

util$plot_num_leapfrogs_by_chain(diagnostics_m2_nonmarg)
```

## Comparing Adapted Step Sizes

Each chain adapts its own step size. Large variation between chains, or very small step sizes, can indicate geometric problems.

```{r}
#| label: stepsizes

util$display_stepsizes(diagnostics_m2_nonmarg)
```

## Distribution of Divergences (if any)

```{r}
#| label: fig-div-marginal-sigma-b
#| fig-cap: "Marginal distribution of sigma_b: divergent (green) vs non-divergent (gray)"

divs <- diagnostics_m2_nonmarg[['divergent__']]
div_idx <- which(c(t(divs)) == 1)
nondiv_idx <- which(c(t(divs)) == 0)

sigma_b_vals <- c(t(samples_m2_nonmarg[['sigma_b']]))

hist(sigma_b_vals[nondiv_idx], breaks = 30, col = "gray80", border = "gray60",
     main = "", xlab = "sigma_b", freq = FALSE)
if (length(div_idx) > 0) {
  hist(sigma_b_vals[div_idx], breaks = 30, col = rgb(0, 1, 0, 0.5),
       border = "darkgreen", add = TRUE, freq = FALSE)
  legend("topright", c("Non-divergent", "Divergent"),
         fill = c("gray80", rgb(0, 1, 0, 0.5)))
}
```

If divergences cluster at small σ_b values, this confirms the funnel geometry problem.

```{r}
  K <- 3
  rho <- rep(1/3, K)  # Symmetric baseline

  # Explore different tau values
  tau_values <- c(0.1, 0.25, 0.5, 1.0, 2.0)
  n_samples <- 2000

  par(mfrow = c(2, 3))

  for (tau in tau_values) {
    # Sample simplices from Dirichlet
    p_samples <- util$rdirichlet(n_samples, rho, tau)

    alpha <- rho / tau + 1

    # Boxplot of category probabilities
    boxplot(p_samples, names = c("P(R=1)", "P(R=2)", "P(R=3)"),
            main = paste0("tau = ", tau, "\nalpha = (",
                          round(alpha[1], 2), ", ",
                          round(alpha[2], 2), ", ",
                          round(alpha[3], 2), ")"),
            ylim = c(0, 1), col = c(util$c_dark, util$c_mid_highlight, util$c_light))
    abline(h = 1/3, lty = 2, col = "gray")
  }

  # Cutpoint distributions
  par(mfrow = c(2, 3))

  for (tau in tau_values) {
    p_samples <- util$rdirichlet(n_samples, rho, tau)

    # Derive cutpoints for each sample
    cuts <- t(apply(p_samples, 1, util$derived_cut_points))

    plot(cuts[, 1], cuts[, 2], pch = 16, cex = 0.3, col = rgb(0, 0, 0, 0.2),
         xlim = c(-4, 4), ylim = c(-4, 4),
         xlab = "c1", ylab = "c2",
         main = paste0("Cutpoints: tau = ", tau))
    abline(h = 0, v = 0, lty = 2, col = "gray")
  }
```

# Model 4: Task Burden with Resources

## Model Structure

We extend Model 3 to include the ordinal resources variable. Task burden now generates three outcomes: forecasts, resources, and completion times.

$$\text{task_burden}_n \sim \text{Normal}(0, \sigma_b)$$

**Forecasts** (as in M3): $$\text{forecast}_n = 5 \cdot (Z_n + 1), \quad Z_n \sim \text{NegBinomial2}(\exp(\alpha_f + \text{task_burden}_n), \phi)$$

**Resources** (ordinal 1-3): $$\text{resources}_n \sim \text{OrderedLogistic}(\lambda_r \cdot \text{task_burden}_n, \mathbf{c})$$

where cutpoints $\mathbf{c}$ are derived from a Dirichlet prior on baseline probabilities: $$\mathbf{p} \sim \text{Dirichlet}(\boldsymbol{\alpha}), \quad \boldsymbol{\alpha} = \boldsymbol{\rho}/\tau + \mathbf{1}$$ $$c_1 = \text{logit}(p_1), \quad c_2 = \text{logit}(p_1 + p_2)$$

**Completion time**: $$y_n \sim \text{Lognormal}(\alpha_t + \beta_{\text{trt}} \cdot \text{ai_access}_n + \beta_{\text{burden}} \cdot \text{task_burden}_n, \sigma_t)$$

## Prior Development

### Parameters from M3 (unchanged)

| Parameter | Prior | Interpretation |
|----|----|----|
| $\sigma_b$ | Half-Normal(0, 0.39) | Task burden spread; 99% \< 1 |
| $\sigma_t$ | Half-Normal(0, 0.25) | Completion noise; 99% \< 0.64 |
| $\kappa$ | Half-Normal(0, 0.10) | Forecast overdispersion |
| $\alpha_f$ | Normal(log(17), 0.30) | Log expected (forecast/5 - 1) |
| $\alpha_t$ | Normal(log(90), 0.40) | Log median completion |
| $\beta_{\text{burden}}$ | Normal(1, 0.32) | Burden → completion; 0.25-1.75 |
| $\beta_{\text{trt}}$ | Normal(0, 0.7) | Treatment effect |

### New parameters for resources

| Parameter | Prior | Interpretation |
|----|----|----|
| $\boldsymbol{\rho}$ | (1/3, 1/3, 1/3) | Symmetric baseline for Dirichlet |
| $\tau$ | 0.2 (fixed) | Dirichlet concentration; $\alpha = (2.67, 2.67, 2.67)$ |
| $\lambda_r$ | Normal(1, 0.43) | Burden → resources; positive, 99% \< 2 |

## Prior Predictive Check

```{r}
#| label: model4-prior-data

stan_data_m4_prior <- list(
  N = sum(complete_idx),
  ai_access = dat$ai_access[complete_idx],
  rho = rep(1/3, 3),
  tau = 0.2
)
```

```{r}
#| label: model4-prior-fit

fit_prior_m4 <- stan(
  file = "stan_programs/model4_prior.stan",
  data = stan_data_m4_prior,
  algorithm = "Fixed_param",
  iter = 1000,
  chains = 1,
  seed = 4321
)

samples_prior_m4 <- util$extract_expectand_vals(fit_prior_m4)
```

### Prior on lambda_r (burden → resources coefficient)

```{r}
#| label: fig-m4-prior-lambda-r
#| fig-cap: "Prior on lambda_r: effect of task burden on resource needs"

util$plot_line_hist(samples_prior_m4$lambda_r, -1, 3, 0.1,
                    xlab = "lambda_r")
abline(v = 0, lty = 2, lwd = 2)
abline(v = 1, lty = 1, lwd = 1, col = "gray")
```

### Prior on baseline probabilities

```{r}
#| label: fig-m4-prior-baseline-probs
#| fig-cap: "Prior on baseline ordinal probabilities (at eta = 0)"

par(mfrow = c(1, 3))
for (k in 1:3) {
  util$plot_line_hist(samples_prior_m4[[paste0("baseline_p[", k, "]")]],
                      0, 1, 0.05,
                      xlab = paste0("P(R = ", k, ")"),
                      main = paste0("Baseline P(R = ", k, ")"))
  abline(v = 1/3, lty = 2, lwd = 2, col = "red")
}
```

### Prior on cut points

```{r}
#| label: fig-m4-prior-cutpoints
#| fig-cap: "Prior on derived cut points"

par(mfrow = c(1, 2))
util$plot_line_hist(samples_prior_m4[["cut_points[1]"]], -3, 3, 0.15,
                    xlab = "c1", main = "Cut point 1")
abline(v = 0, lty = 2, lwd = 2)

util$plot_line_hist(samples_prior_m4[["cut_points[2]"]], -3, 3, 0.15,
                    xlab = "c2", main = "Cut point 2")
abline(v = 0, lty = 2, lwd = 2)
```

### Prior predictive: simulated resource distribution

```{r}
#| label: fig-m4-prior-resources-dist
#| fig-cap: "Prior predictive: proportion in each resource category"

par(mfrow = c(1, 3))
util$plot_line_hist(samples_prior_m4$prop_resources_1, 0, 1, 0.025,
                    xlab = "Proportion", main = "P(R = 1) in simulated data")
abline(v = 1/3, lty = 2, lwd = 2)

util$plot_line_hist(samples_prior_m4$prop_resources_2, 0, 1, 0.025,
                    xlab = "Proportion", main = "P(R = 2) in simulated data")
abline(v = 1/3, lty = 2, lwd = 2)

util$plot_line_hist(samples_prior_m4$prop_resources_3, 0, 1, 0.025,
                    xlab = "Proportion", main = "P(R = 3) in simulated data")
abline(v = 1/3, lty = 2, lwd = 2)
```

### Prior predictive: forecasts

```{r}
#| label: fig-m4-prior-forecast
#| fig-cap: "Model 4 prior predictive: forecast times (minutes)"

util$plot_hist_quantiles(samples_prior_m4, 'forecast_sim', 0, 800, 25,
                         xlab = "Forecast time (minutes)")
abline(v = 10, lty = 2, lwd = 2)
abline(v = 1440, lty = 2, lwd = 2)
```

### Prior predictive: completion times

```{r}
#| label: fig-m4-prior-y
#| fig-cap: "Model 4 prior predictive: completion time (minutes)"

util$plot_hist_quantiles(samples_prior_m4, 'y_sim', 0, 1500, 25,
                         xlab = "Completion time (minutes)")
abline(v = 10, lty = 2, lwd = 2)
abline(v = 1440, lty = 2, lwd = 2)
```

### Prior predictive: log completion time

```{r}
#| label: fig-m4-prior-log-y
#| fig-cap: "Model 4 prior predictive: log completion time"

util$plot_hist_quantiles(samples_prior_m4, 'log_y_sim', 0, 10, 0.25,
                         xlab = "log(completion time)")
abline(v = log(10), lty = 2, lwd = 2)
abline(v = log(1440), lty = 2, lwd = 2)
```

### Prior on treatment effect

```{r}
#| label: fig-m4-prior-ate-pct
#| fig-cap: "Model 4 prior: treatment effect (% change)"

pct_lift_m4_prior <- (exp(samples_prior_m4$beta_trt) - 1) * 100
util$plot_line_hist(pct_lift_m4_prior, -100, 500, 20,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)
abline(v = -95, lty = 2, lwd = 2)
abline(v = 400, lty = 2, lwd = 2)
```

## Model Fitting

```{r}
#| label: model4-fit-data

# Prepare resources data (handle missingness)
dat_complete <- dat[complete_idx, ]

# Recode resources: 5 -> 3 (as done earlier in EDA)
resources_raw <- dat_complete$external_resource_needs_1_to_3
resources_raw[resources_raw == 5] <- 3

# Indices of observed resources
obs_resources_idx <- which(!is.na(resources_raw))

stan_data_m4 <- list(
  N = sum(complete_idx),
  y = dat$total_time[complete_idx],
  forecast = dat$forecast[complete_idx],
  ai_access = dat$ai_access[complete_idx],

  # Resources with missingness
  N_obs_resources = length(obs_resources_idx),
  resources_idx = obs_resources_idx,
  resources = resources_raw[obs_resources_idx],

  # Dirichlet hyperparameters
  rho = rep(1/3, 3),
  tau = 0.2
)
```

```{r}
#| label: model4-fit

fit_m4 <- stan(
  file = "stan_programs/model4.stan",
  data = stan_data_m4,
  seed = 12131415,
  iter = 4000,
  refresh = 200,
  control = list(adapt_delta = 0.9)
)
```

```{r}
#| label: model4-diagnostics

util$check_all_hmc_diagnostics(util$extract_hmc_diagnostics(fit_m4))
samples_m4 <- util$extract_expectand_vals(fit_m4)
base_samples_m4 <- util$filter_expectands(samples_m4,
  c('beta_trt', 'alpha_f', 'alpha_t', 'beta_burden', 'lambda_r',
    'sigma_b', 'sigma_t', 'kappa'))  # phi = 1/kappa has tail issues, monitor kappa instead
util$check_all_expectand_diagnostics(base_samples_m4)
```

## Posterior Retrodictive Checks

### Log completion time

```{r}
#| label: fig-m4-retro-log-y
#| fig-cap: "Model 4 posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples_m4, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m4$y),
                         xlab = "log(completion time)")
```

### Forecast time

```{r}
#| label: fig-m4-retro-forecast
#| fig-cap: "Model 4 posterior retrodictive: forecast time"

util$plot_hist_quantiles(samples_m4, 'forecast_pred', 0, 800, 25,
                         baseline_values = stan_data_m4$forecast,
                         xlab = "Forecast time (minutes)")
```

### Resources distribution

```{r}
#| label: fig-m4-retro-resources
#| fig-cap: "Model 4 posterior retrodictive: resources distribution (observed cases)"

# Subset predictions to observed indices only
resources_pred_obs <- samples_m4[paste0('resources_pred[', obs_resources_idx, ']')]
names(resources_pred_obs) <- paste0('resources_pred_obs[', seq_along(obs_resources_idx), ']')

util$plot_hist_quantiles(resources_pred_obs, 'resources_pred_obs', 0.5, 3.5, 1,
                         baseline_values = stan_data_m4$resources,
                         xlab = "Resources (1-3)")
```

### Treatment effect (percentage lift)

```{r}
#| label: fig-m4-retro-ate-pct
#| fig-cap: "Model 4 posterior: treatment effect (% change)"

y_ai <- dat$total_time[complete_idx & dat$ai_access == 1]
y_no_ai <- dat$total_time[complete_idx & dat$ai_access == 0]
observed_pct_diff <- (median(y_ai) / median(y_no_ai) - 1) * 100

util$plot_line_hist(samples_m4$pct_lift, -80, 80, 5,
                    xlab = "Treatment effect (% change)")
abline(v = 0, lty = 1, lwd = 1)
abline(v = observed_pct_diff, lty = 2, lwd = 2)
```

### Parameter summaries

```{r}
#| label: model4-summary

print(fit_m4, pars = c("alpha_f", "alpha_t", "beta_burden", "beta_trt", "lambda_r",
                        "sigma_b", "sigma_t", "kappa", "phi",
                        "baseline_p", "cut_points", "pct_lift"))
```

### Prior vs Posterior: lambda_r

```{r}
#| label: fig-m4-prior-post-lambda-r
#| fig-cap: "Model 4: Prior (teal) vs Posterior for lambda_r"

util$plot_expectand_pushforward(samples_m4[["lambda_r"]], 25,
                                display_name = "lambda_r", flim = c(-1, 3))
xs <- seq(-1, 3, 0.01)
ys <- dnorm(xs, 1, 0.43)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

### Prior vs Posterior: baseline probabilities

```{r}
#| label: fig-m4-prior-post-baseline-p
#| fig-cap: "Model 4: Posterior baseline probabilities"

par(mfrow = c(1, 3))
for (k in 1:3) {
  util$plot_expectand_pushforward(samples_m4[[paste0("baseline_p[", k, "]")]], 25,
                                  display_name = paste0("baseline_p[", k, "]"),
                                  flim = c(0, 1))
  abline(v = 1/3, lty = 2, lwd = 2, col = c_light_teal)
}
```

### Compare treatment effects across models

```{r}
#| label: fig-compare-ate-m4
#| fig-cap: "Comparison: treatment effect estimates across all models"

util$plot_line_hist(samples$pct_lift, -80, 80, 5,
                    xlab = "Treatment effect (% change)", col = 'blue', prob = TRUE)
util$plot_line_hist(samples_m2$pct_lift, -80, 80, 5, add = TRUE,
                    col = 'darkgreen', prob = TRUE)
util$plot_line_hist(samples_m3$pct_lift, -80, 80, 5, add = TRUE,
                    col = 'darkorange', prob = TRUE)
util$plot_line_hist(samples_m4$pct_lift, -80, 80, 5, add = TRUE,
                    col = 'purple', prob = TRUE)
legend("topright", c("Model 1", "Model 2", "Model 3", "Model 4"),
       fill = c('blue', 'darkgreen', 'darkorange', 'purple'))
```

## Appendix: Investigating E-FMI in Model 4

Low E-FMI indicates the sampler's momentum isn't helping explore efficiently. We diagnose this by examining the relationship between the hierarchical scale parameter (sigma_b) and the latent task_burden parameters.

### Extract diagnostics

```{r}
#| label: m4-diagnostics-extract

diagnostics_m4 <- util$extract_hmc_diagnostics(fit_m4)
```

### Visualizing the Funnel

The characteristic funnel shape: when sigma_b is small, task_burden is constrained near zero; when sigma_b is large, task_burden spreads out.

```{r}
#| label: fig-m4-funnel
#| fig-cap: "Model 4 funnel geometry: sigma_b vs selected task_burden parameters"
#| fig-width: 10
#| fig-height: 8

util$plot_div_pairs(
  x_names = c("sigma_b"),
  y_names = c("task_burden[1]", "task_burden[10]", "task_burden[50]",
              "task_burden[100]", "task_burden[150]", "task_burden[200]"),
  expectand_vals_list = samples_m4,
  diagnostics = diagnostics_m4,
  transforms = list("sigma_b" = 1),
  plot_mode = 0
)
```

### Chain Mixing in Funnel Space

Colors indicate iteration order (light = early, dark = late). Well-mixing chains show interspersed colors; poorly-mixing chains show gradients or clusters.

```{r}
#| label: fig-m4-pairs-chain
#| fig-cap: "Model 4 pairs by chain: sigma_b vs task_burden[1]"
#| fig-width: 10
#| fig-height: 8

util$plot_pairs_by_chain(
  samples_m4[["sigma_b"]], "sigma_b",
  samples_m4[["task_burden[1]"]], "task_burden[1]"
)

util$plot_pairs_by_chain(
    samples_m4[["sigma_b"]], "sigma_b",
    samples_m4[["beta_burden"]], "beta_burden"
  )

  util$plot_pairs_by_chain(
    samples_m4[["sigma_b"]], "sigma_b",
    samples_m4[["sigma_t"]], "sigma_t"
  )

  util$plot_pairs_by_chain(
    samples_m4[["kappa"]], "kappa",
    samples_m4[["alpha_f"]], "alpha_f"
  )

  util$plot_pairs_by_chain(
    samples_m4[["sigma_b"]], "sigma_b",
    samples_m4[["kappa"]], "kappa"
  )
```

### Trajectory Lengths

Unusual trajectory patterns indicate geometric problems. Very short trajectories suggest the sampler is U-turning quickly.

```{r}
#| label: fig-m4-leapfrogs
#| fig-cap: "Model 4: Distribution of trajectory lengths by chain"

util$plot_num_leapfrogs_by_chain(diagnostics_m4)
```

### Adapted Step Sizes

Large variation between chains or very small step sizes indicate geometric problems.

```{r}
#| label: m4-stepsizes

util$display_stepsizes(diagnostics_m4)
```

### Divergence Distribution

```{r}
#| label: fig-m4-div-sigma-b
#| fig-cap: "Model 4: sigma_b distribution with divergences highlighted"

divs <- diagnostics_m4[['divergent__']]
div_idx <- which(c(t(divs)) == 1)
nondiv_idx <- which(c(t(divs)) == 0)

sigma_b_vals <- c(t(samples_m4[['sigma_b']]))

util$plot_line_hist(sigma_b_vals[nondiv_idx], 0, 1.5, 0.05,
                    xlab = "sigma_b", main = "sigma_b: non-divergent samples")
if (length(div_idx) > 0) {
  util$plot_line_hist(sigma_b_vals[div_idx], 0, 1.5, 0.05,
                      col = "darkgreen", add = TRUE)
  legend("topright", c("Non-divergent", "Divergent"),
         fill = c("black", "darkgreen"))
}
```

If divergences cluster at small sigma_b values, this confirms the funnel neck is problematic.

### Investigating lambda_r Boundary Issue

The posterior for lambda_r appears to want negative values but is constrained positive.

```{r}
#| label: fig-m4-lambda-r-posterior
#| fig-cap: "Posterior of lambda_r (constrained positive)"

util$plot_line_hist(samples_m4$lambda_r, 0, 3, 0.1,
                    xlab = "lambda_r")
abline(v = 0, lty = 2, lwd = 2, col = "red")
```

```{r}
#| label: fig-m4-lambda-r-pairs
#| fig-cap: "lambda_r vs other parameters"
#| fig-width: 10
#| fig-height: 8

par(mfrow = c(2, 2))
util$plot_pairs_by_chain(
  samples_m4[["lambda_r"]], "lambda_r",
  samples_m4[["sigma_b"]], "sigma_b"
)
```

```{r}
#| label: fig-m4-lambda-r-beta-burden
#| fig-width: 10
#| fig-height: 8

util$plot_pairs_by_chain(
  samples_m4[["lambda_r"]], "lambda_r",
  samples_m4[["beta_burden"]], "beta_burden"
)
```

### Raw Data Check: Task Burden vs Resources

Do the inferred task burdens relate to observed resources as expected?

```{r}
#| label: fig-m4-burden-resources-check

# Get posterior mean of task_burden for each observation
task_burden_means <- sapply(1:stan_data_m4$N, function(n) {
  mean(samples_m4[[paste0("task_burden[", n, "]")]])
})

# Plot task_burden vs observed resources (for observed cases)
par(mfrow = c(1, 2))

# Boxplot of task_burden by resource level
boxplot(task_burden_means[obs_resources_idx] ~ stan_data_m4$resources,
        xlab = "Resources (1-3)", ylab = "Posterior mean task_burden",
        main = "Task burden by resource level")

# Should see: higher resources → higher task_burden if lambda_r > 0 makes sense
# If pattern is reversed, domain assumption may be wrong

# Also check cutpoints
cat("Posterior mean cut_points:\n")
cat("  c1:", mean(samples_m4[["cut_points[1]"]]), "\n")
cat("  c2:", mean(samples_m4[["cut_points[2]"]]), "\n")

cat("\nPosterior mean baseline_p:\n")
for (k in 1:3) {
  cat("  p[", k, "]:", mean(samples_m4[[paste0("baseline_p[", k, "]")]]), "\n")
}

names <- paste0('task_burden[', stan_data_m4$resources_idx, ']')
util$plot_conditional_mean_quantiles(samples_m4,names = names, obs_xs = stan_data_m4$resources, bin_min = 0.5, bin_max = 3.5, bin_delta=1 )
```

### Check: Is the Sign Convention Correct?

In ordered logistic with Betancourt's convention: - `P(y <= k) = inv_logit(c_k - gamma)` - Positive gamma → probability mass shifts to HIGHER categories

So if `gamma = lambda_r * task_burden`: - Higher task_burden with lambda_r \> 0 → higher gamma → higher resource category

This is what we want. But if the data shows the opposite pattern, either: 1. Task burden is capturing something different than we think 2. Resources variable means something different 3. There's confounding we haven't modeled

```{r}
#| label: check-model-sign

# Direct check: what's the empirical correlation between
# inferred task_burden and resources?
cor_burden_resources <- cor(task_burden_means[obs_resources_idx],
                            stan_data_m4$resources)
cat("Correlation(task_burden, resources):", round(cor_burden_resources, 3), "\n")

# If this is NEGATIVE, task_burden is inversely related to resources,
# which contradicts our domain assumption
```

# Model 5: Developer Comfort + Task Burden

## Model Structure

Model 5 extends Model 4 by adding a hierarchical developer-level latent variable (`comfort`) alongside the observation-level `task_burden`. This allows us to capture systematic between-developer differences.

**Latent structure:**

-   `comfort_j ~ Normal(0, sigma_c)` (developer-level, J developers)
-   `task_burden_n ~ Normal(0, sigma_b)` (observation-level, N tasks)
-   `gap_n = task_burden_n - comfort_j` (key derived quantity)

**Outcomes:**

-   `exposure ~ OrderedLogistic(lambda_e * comfort, cut_points_e)` (K=5)
-   `resources ~ OrderedLogistic(lambda_r * gap, cut_points_r)` (K=3)
-   `forecast ~ NegBinomial2(exp(alpha_f + gap), phi)` (identification: gap coef = 1)
-   `y ~ Lognormal(alpha_t + beta_gap * gap + beta_trt * ai, sigma_t)`

**Identification:** Gap coefficient fixed to 1 in forecast (identifies latent scale).

## Prior Development

### Model 5 Parameters

| Parameter | Prior                 | Interpretation                 |
|-----------|-----------------------|--------------------------------|
| sigma_c   | HalfNormal(0, 0.78)   | Developer comfort spread       |
| sigma_b   | HalfNormal(0, 0.39)   | Task burden spread             |
| sigma_t   | HalfNormal(0, 0.25)   | Completion time noise          |
| kappa     | HalfNormal(0, 0.10)   | Forecast overdispersion        |
| alpha_f   | Normal(log(17), 0.30) | Log expected forecast baseline |
| alpha_t   | Normal(log(90), 0.40) | Log median completion baseline |
| beta_gap  | Normal(1, 0.3)        | Gap → completion (calibration) |
| beta_trt  | Normal(0, 0.7)        | Treatment effect               |
| lambda_e  | Normal(1, 0.43)       | Comfort → exposure (+)         |
| lambda_r  | Normal(1, 0.43)       | Gap → resources (+)            |

## Prior Predictive Check

```{r}
#| label: model5-prior-data

# Build data for Model 5 prior predictive
stan_data_m5_prior <- list(
  N = nrow(dat),
  J = length(unique(dat$dev_num)),
  dev_idx = dat$dev_num,
  ai_access = dat$ai_access,

  # Dirichlet hyperparameters for exposure (K=5)
  rho_e = rep(1/5, 5),
  tau_e = 0.1,

  # Dirichlet hyperparameters for resources (K=3)
  rho_r = rep(1/3, 3),
  tau_r = 0.2
)

cat("N observations:", stan_data_m5_prior$N, "\n")
cat("J developers:", stan_data_m5_prior$J, "\n")
```

```{r}
#| label: model5-prior-fit

fit_prior_m5 <- stan(
  file = "stan_programs/model5_prior.stan",
  data = stan_data_m5_prior,
  algorithm = "Fixed_param",
  iter = 1000,
  chains = 1,
  seed = 5432
)

samples_prior_m5 <- util$extract_expectand_vals(fit_prior_m5)
```

### Prior on sigma_c (developer comfort spread)

```{r}
#| label: fig-m5-prior-sigma-c
#| fig-cap: "Model 5 prior: sigma_c (developer comfort spread)"

util$plot_line_hist(samples_prior_m5$sigma_c, 0, 2.5, 0.1,
                    xlab = "sigma_c")
abline(v = 2, lty = 2, col = "red")
```

### Prior on beta_gap (gap → completion time)

```{r}
#| label: fig-m5-prior-beta-gap
#| fig-cap: "Model 5 prior: beta_gap (gap effect on completion time)"

util$plot_line_hist(samples_prior_m5$beta_gap, -0.5, 2.5, 0.1,
                    xlab = "beta_gap")
abline(v = 0, lty = 2, col = "gray")
abline(v = 1, lty = 1, col = "gray")
```

### Prior on lambda_e (comfort → exposure)

```{r}
#| label: fig-m5-prior-lambda-e
#| fig-cap: "Model 5 prior: lambda_e (comfort effect on exposure)"

util$plot_line_hist(samples_prior_m5$lambda_e, -1, 3, 0.1,
                    xlab = "lambda_e")
abline(v = 0, lty = 2, col = "gray")
abline(v = 1, lty = 1, col = "gray")
```

### Prior on lambda_r (gap → resources)

```{r}
#| label: fig-m5-prior-lambda-r
#| fig-cap: "Model 5 prior: lambda_r (gap effect on resources)"

util$plot_line_hist(samples_prior_m5$lambda_r, -1, 3, 0.1,
                    xlab = "lambda_r")
abline(v = 0, lty = 2, col = "gray")
abline(v = 1, lty = 1, col = "gray")
```

### Prior on baseline probabilities: exposure (K=5)

```{r}
#| label: fig-m5-prior-baseline-probs-exposure
#| fig-cap: "Model 5 prior: baseline exposure probabilities (at gamma = 0)"

par(mfrow = c(2, 3))
for (k in 1:5) {
  util$plot_line_hist(samples_prior_m5[[paste0("baseline_p_e[", k, "]")]],
                      0, 1, 0.05,
                      xlab = paste0("P(E = ", k, ")"),
                      main = paste0("Baseline P(E = ", k, ")"))
  abline(v = 1/5, lty = 2, lwd = 2, col = "red")
}
```

### Prior on baseline probabilities: resources (K=3)

```{r}
#| label: fig-m5-prior-baseline-probs-resources
#| fig-cap: "Model 5 prior: baseline resources probabilities (at gamma = 0)"

par(mfrow = c(1, 3))
for (k in 1:3) {
  util$plot_line_hist(samples_prior_m5[[paste0("baseline_p_r[", k, "]")]],
                      0, 1, 0.05,
                      xlab = paste0("P(R = ", k, ")"),
                      main = paste0("Baseline P(R = ", k, ")"))
  abline(v = 1/3, lty = 2, lwd = 2, col = "red")
}
```

### Prior on cut points: exposure

```{r}
#| label: fig-m5-prior-cutpoints-exposure
#| fig-cap: "Model 5 prior: exposure cut points"

par(mfrow = c(2, 2))
for (k in 1:4) {
  util$plot_line_hist(samples_prior_m5[[paste0("cut_points_e[", k, "]")]],
                      -4, 4, 0.2,
                      xlab = paste0("c_e[", k, "]"),
                      main = paste0("Cut point ", k))
  abline(v = 0, lty = 2, lwd = 2)
}
```

### Prior on cut points: resources

```{r}
#| label: fig-m5-prior-cutpoints-resources
#| fig-cap: "Model 5 prior: resources cut points"

par(mfrow = c(1, 2))
util$plot_line_hist(samples_prior_m5[["cut_points_r[1]"]], -3, 3, 0.15,
                    xlab = "c_r[1]", main = "Cut point 1")
abline(v = 0, lty = 2, lwd = 2)

util$plot_line_hist(samples_prior_m5[["cut_points_r[2]"]], -3, 3, 0.15,
                    xlab = "c_r[2]", main = "Cut point 2")
abline(v = 0, lty = 2, lwd = 2)
```

### Prior predictive: simulated exposure distribution

```{r}
#| label: fig-m5-prior-exposure
#| fig-cap: "Model 5 prior predictive: exposure distribution"

util$plot_hist_quantiles(samples_prior_m5, 'exposure_sim', 0.5, 5.5, 1,
                         xlab = "Exposure (1-5)")
```

### Prior predictive: simulated resources distribution

```{r}
#| label: fig-m5-prior-resources
#| fig-cap: "Model 5 prior predictive: resources distribution"

util$plot_hist_quantiles(samples_prior_m5, 'resources_sim', 0.5, 3.5, 1,
                         xlab = "Resources (1-3)")
```

### Prior predictive: simulated forecasts

```{r}
#| label: fig-m5-prior-forecast
#| fig-cap: "Model 5 prior predictive: forecast times (minutes)"

util$plot_hist_quantiles(samples_prior_m5, 'forecast_sim', 0, 800, 25,
                         xlab = "Forecast time (minutes)")
abline(v = 10, lty = 2, lwd = 2)
abline(v = 1440, lty = 2, lwd = 2)
util$my_q(samples_prior_m5[['forecast_sim[1]']])
```

### Prior predictive: simulated completion times

```{r}
#| label: fig-m5-prior-y
#| fig-cap: "Model 5 prior predictive: completion time (minutes)"

util$plot_hist_quantiles(samples_prior_m5, 'y_sim', 0, 1500, 25,
                         xlab = "Completion time (minutes)")
abline(v = 10, lty = 2, lwd = 2)
abline(v = 1440, lty = 2, lwd = 2)
```

### Prior predictive: log completion time

```{r}
#| label: fig-m5-prior-log-y
#| fig-cap: "Model 5 prior predictive: log completion time"

util$plot_hist_quantiles(samples_prior_m5, 'log_y_sim', 0, 10, 0.25,
                         xlab = "log(completion time)")
abline(v = log(10), lty = 2, lwd = 2)
abline(v = log(1440), lty = 2, lwd = 2)
util$my_q(samples_prior_m5[['y_sim[1]']])
```

### Prior on treatment effect (percentage lift)

```{r}
#| label: fig-m5-prior-pct-lift
#| fig-cap: "Model 5 prior: treatment effect (% change)"

util$plot_line_hist(samples_prior_m5$pct_lift, -80, 200, 10,
                    xlab = "% change in completion time")
abline(v = 0, lty = 2, col = "gray")
util$my_q(samples_prior_m5$pct_lift)
```

### Summary statistics

```{r}
#| label: m5-prior-summary

cat("Prior predictive summary:\n\n")

cat("Mean exposure by draw:\n")
print(util$my_q(samples_prior_m5$mean_exposure))

cat("\nMean resources by draw:\n")
print(util$my_q(samples_prior_m5$mean_resources))
```

## Model Fitting

```{r}
#| label: model5-fit-data

# Use same complete cases as Model 4
dat_complete_m5 <- dat[complete_idx, ]

# Exposure (ordinal 1-5)
exposure_raw <- dat_complete_m5$prior_task_exposure_1_to_5
obs_exposure_idx <- which(!is.na(exposure_raw))

# Resources (ordinal 1-3, recode 5 -> 3)
resources_raw_m5 <- dat_complete_m5$external_resource_needs_1_to_3
resources_raw_m5[resources_raw_m5 == 5] <- 3
obs_resources_idx_m5 <- which(!is.na(resources_raw_m5))

# Developer indices
dev_idx_m5 <- dat_complete_m5$dev_num

stan_data_m5 <- list(
  N = sum(complete_idx),
  J = length(unique(dev_idx_m5)),
  dev_idx = dev_idx_m5,

  y = dat_complete_m5$total_time,
  forecast = dat_complete_m5$forecast,
  ai_access = dat_complete_m5$ai_access,

  # Exposure (with missingness)
  N_obs_exposure = length(obs_exposure_idx),
  exposure_idx = obs_exposure_idx,
  exposure = exposure_raw[obs_exposure_idx],

  # Resources (with missingness)
  N_obs_resources = length(obs_resources_idx_m5),
  resources_idx = obs_resources_idx_m5,
  resources = resources_raw_m5[obs_resources_idx_m5],

  # Dirichlet hyperparameters
  rho_e = rep(1/5, 5),
  tau_e = 0.1,
  rho_r = rep(1/3, 3),
  tau_r = 0.2
)

cat("N observations:", stan_data_m5$N, "\n")
cat("J developers:", stan_data_m5$J, "\n")
cat("N observed exposure:", stan_data_m5$N_obs_exposure, "\n")
cat("N observed resources:", stan_data_m5$N_obs_resources, "\n")
```

```{r}
#| label: model5-fit

fit_m5 <- stan(
  file = "stan_programs/model5.stan",
  data = stan_data_m5,
  chains = 4,
  iter = 8000,
  warmup = 4000,
  seed = 54321,
  control = list(adapt_delta = 0.99)
)
```

```{r}
#| label: model5-diagnostics

util$check_all_hmc_diagnostics(util$extract_hmc_diagnostics(fit_m5))
samples_m5 <- util$extract_expectand_vals(fit_m5)
base_samples_m5 <- util$filter_expectands(samples_m5,
  c('beta_gap', 'beta_trt', 'alpha_f', 'alpha_t',
    'lambda_e', 'lambda_r',
    'sigma_c', 'sigma_b', 'sigma_t', 'kappa'))
util$check_all_expectand_diagnostics(base_samples_m5)
```

## Posterior Retrodictive Checks

### Log completion time

```{r}
#| label: fig-m5-retro-log-y
#| fig-cap: "Model 5 posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples_m5, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m5$y),
                         xlab = "log(completion time)")
```

### Forecast time

```{r}
#| label: fig-m5-retro-forecast
#| fig-cap: "Model 5 posterior retrodictive: forecast time"

util$plot_hist_quantiles(samples_m5, 'forecast_pred', 0, 800, 25,
                         baseline_values = stan_data_m5$forecast,
                         xlab = "Forecast time (minutes)", main='model 5')
```

### Exposure distribution

```{r}
#| label: fig-m5-retro-exposure
#| fig-cap: "Model 5 posterior retrodictive: exposure distribution (observed cases)"

exposure_pred_obs <- samples_m5[paste0('exposure_pred[', obs_exposure_idx, ']')]
names(exposure_pred_obs) <- paste0('exposure_pred_obs[', seq_along(obs_exposure_idx), ']')

util$plot_hist_quantiles(exposure_pred_obs, 'exposure_pred_obs', 0.5, 5.5, 1,
                         baseline_values = stan_data_m5$exposure,
                         xlab = "Exposure (1-5)")
```

### Resources distribution

```{r}
#| label: fig-m5-retro-resources
#| fig-cap: "Model 5 posterior retrodictive: resources distribution (observed cases)"

resources_pred_obs_m5 <- samples_m5[paste0('resources_pred[', obs_resources_idx_m5, ']')]
names(resources_pred_obs_m5) <- paste0('resources_pred_obs[', seq_along(obs_resources_idx_m5), ']')

util$plot_hist_quantiles(resources_pred_obs_m5, 'resources_pred_obs', 0.5, 3.5, 1,
                         baseline_values = stan_data_m5$resources,
                         xlab = "Resources (1-3)")
```

### Treatment effect (percentage lift)

```{r}
#| label: fig-m5-post-pct-lift
#| fig-cap: "Model 5 posterior: treatment effect (% change)"

util$plot_line_hist(samples_m5$pct_lift, -60, 60, 2.5,
                    xlab = "% change in completion time")
abline(v = 0, lty = 2, lwd = 2)

cat("Treatment effect (% lift):\n")
util$my_q(samples_m5$pct_lift)
```

### Parameter summaries

```{r}
#| label: m5-param-summary

print(fit_m5, pars = c("sigma_c", "sigma_b", "sigma_t", "kappa",
                        "alpha_f", "alpha_t",
                        "beta_gap", "beta_trt",
                        "lambda_e", "lambda_r"))
```

### Prior vs Posterior: key parameters

```{r}
#| label: fig-m5-prior-post-sigma-c
#| fig-cap: "Model 5: Prior (teal) vs Posterior for sigma_c"

util$plot_expectand_pushforward(samples_m5[["sigma_c"]], 25,
                                display_name = "sigma_c", flim = c(0, 2.5))
xs <- seq(0, 2.5, 0.01)
ys <- 2 * dnorm(xs, 0, 0.78)  # Half-Normal(0, 0.78)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m5-prior-post-beta-gap
#| fig-cap: "Model 5: Prior (teal) vs Posterior for beta_gap"

util$plot_expectand_pushforward(samples_m5[["beta_gap"]], 25,
                                display_name = "beta_gap", flim = c(-0.5, 2.5))
xs <- seq(-0.5, 2.5, 0.01)
ys <- dnorm(xs, 1, 0.3)  # Normal(1, 0.3)
lines(xs, ys, lwd = 2, col = c_light_teal)
abline(v = 1, lty = 2)
```

```{r}
#| label: fig-m5-prior-post-lambda-e
#| fig-cap: "Model 5: Prior (teal) vs Posterior for lambda_e"

util$plot_expectand_pushforward(samples_m5[["lambda_e"]], 25,
                                display_name = "lambda_e", flim = c(-1, 3))
xs <- seq(-1, 3, 0.01)
ys <- dnorm(xs, 1, 0.43)  # Normal(1, 0.43)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m5-prior-post-lambda-r
#| fig-cap: "Model 5: Prior (teal) vs Posterior for lambda_r"

util$plot_expectand_pushforward(samples_m5[["lambda_r"]], 25,
                                display_name = "lambda_r", flim = c(-1, 3))
xs <- seq(-1, 3, 0.01)
ys <- dnorm(xs, 1, 0.43)  # Normal(1, 0.43)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m5-prior-post-kappa
#| fig-cap: "Model 5: Prior (teal) vs Posterior for kappa"

util$plot_expectand_pushforward(samples_m5[["kappa"]], 25,
                                display_name = "kappa", flim = c(0, 0.5))
xs <- seq(0, 0.5, 0.005)
ys <- 2 * dnorm(xs, 0, 0.10)  # Half-Normal(0, 0.10)
lines(xs, ys, lwd = 2, col = c_light_teal)
```

### Compare treatment effects across models

```{r}
#| label: fig-m5-compare-trt
#| fig-cap: "Treatment effect comparison: Models 1-5"

# util$plot_line_hist(samples_m1$pct_lift, -60, 60, 2.5,
#                     xlab = "% change in completion time",
#                     col = util$c_light)
# util$plot_line_hist(samples_m2$pct_lift, -60, 60, 2.5,
#                     col = util$c_mid, add = TRUE)
# util$plot_line_hist(samples_m3$pct_lift, -60, 60, 2.5,
#                     col = util$c_dark, add = TRUE)

util$plot_line_hists(samples_m4$pct_lift, samples_m5$pct_lift, prob = T, col1 = util$c_light, col2=util$c_dark)

abline(v = 0, lty = 2, lwd = 2)

legend("topright", c("Model 4", "Model 5"),
       fill = c(util$c_light, util$c_dark))
```

### Developer comfort estimates

```{r}
#| label: fig-m5-comfort-estimates
#| fig-cap: "Model 5: Posterior developer comfort estimates"

comfort_means <- sapply(1:stan_data_m5$J, function(j) {
  mean(samples_m5[[paste0("comfort[", j, "]")]])
})

comfort_sds <- sapply(1:stan_data_m5$J, function(j) {
  sd(samples_m5[[paste0("comfort[", j, "]")]])
})

# Order by mean comfort
ord <- order(comfort_means)

plot(1:stan_data_m5$J, comfort_means[ord], pch = 19,
     xlab = "Developer (ordered by comfort)",
     ylab = "Comfort",
     ylim = range(comfort_means - 2*comfort_sds, comfort_means + 2*comfort_sds),
     main = "Developer comfort estimates (±2 SD)")
segments(1:stan_data_m5$J, comfort_means[ord] - 2*comfort_sds[ord],
         1:stan_data_m5$J, comfort_means[ord] + 2*comfort_sds[ord])
abline(h = 0, lty = 2)


task_burden_means <- sapply(1:stan_data_m5$N, function(j) {
  mean(samples_m5[[paste0("task_burden[", j, "]")]])
})

task_burden_sds <- sapply(1:stan_data_m5$N, function(j) {
  sd(samples_m5[[paste0("task_burden[", j, "]")]])
})

# Order by mean comfort
ord <- order(task_burden_means)

plot(1:stan_data_m5$N, task_burden_means[ord], pch = 19,
     xlab = "Task (Ordered by Burden)",
     ylab = "Burden",
     ylim = range(task_burden_means - 2*task_burden_sds, task_burden_means + 2*task_burden_sds),
     main = "Task burden estimates (±2 SD)")
segments(1:stan_data_m5$N, task_burden_means[ord] - 2*task_burden_sds[ord],
         1:stan_data_m5$N, task_burden_means[ord] + 2*task_burden_sds[ord])
abline(h = 0, lty = 2)
```

## Appendix: Investigating E-FMI in Model 5

Low E-FMI indicates funnel-like geometry. Model 5 has two potential funnels: sigma_c (developer comfort) and sigma_b (task burden).

### Extract diagnostics

```{r}
#| label: m5-diagnostics-extract

diagnostics_m5 <- util$extract_hmc_diagnostics(fit_m5)
```

### Check sigma_c posterior

Is the model learning anything about developer comfort, or is sigma_c collapsing to zero?

```{r}
#| label: fig-m5-sigma-c-posterior
#| fig-cap: "Model 5: sigma_c posterior vs prior"

util$plot_line_hist(samples_m5$sigma_c, 0, 2.5, 0.05,
                    xlab = "sigma_c", main = "sigma_c posterior")
abline(v = 0, lty = 2)

cat("sigma_c summary:\n")

```

### Funnel: sigma_b vs task_burden

```{r}
#| label: fig-m5-funnel-sigma-b
#| fig-cap: "Model 5 funnel: sigma_b vs task_burden"
#| fig-width: 10
#| fig-height: 8

util$plot_div_pairs(
  x_names = c("sigma_b"),
  y_names = c("task_burden[1]", "task_burden[10]", "task_burden[50]",
              "task_burden[100]", "task_burden[150]", "task_burden[200]"),
  expectand_vals_list = samples_m5,
  diagnostics = diagnostics_m5,
  transforms = list("sigma_b" = 1),
  plot_mode = 0
)
```

### Funnel: sigma_c vs comfort

```{r}
#| label: fig-m5-funnel-sigma-c
#| fig-cap: "Model 5 funnel: sigma_c vs comfort"
#| fig-width: 10
#| fig-height: 6

util$plot_div_pairs(
  x_names = c("sigma_c"),
  y_names = paste0("comfort[", 1:min(stan_data_m5$J, 8), "]"),
  expectand_vals_list = samples_m5,
  diagnostics = diagnostics_m5,
  transforms = list("sigma_c" = 1),
  plot_mode = 0
)
```

### Chain mixing: key parameter pairs

```{r}
#| label: fig-m5-pairs-chain
#| fig-cap: "Model 5 pairs by chain"
#| fig-width: 10
#| fig-height: 8

# sigma_b vs beta_gap
util$plot_pairs_by_chain(
  samples_m5[["sigma_b"]], "sigma_b",
  samples_m5[["beta_gap"]], "beta_gap"
)

# sigma_b vs sigma_t
util$plot_pairs_by_chain(
  samples_m5[["sigma_b"]], "sigma_b",
  samples_m5[["sigma_t"]], "sigma_t"
)

# sigma_c vs sigma_b (interaction between two funnels?)
util$plot_pairs_by_chain(
  samples_m5[["sigma_c"]], "sigma_c",
  samples_m5[["sigma_b"]], "sigma_b"
)

# sigma_c vs beta_gap
util$plot_pairs_by_chain(
  samples_m5[["sigma_c"]], "sigma_c",
  samples_m5[["beta_gap"]], "beta_gap"
)

# kappa vs alpha_f
util$plot_pairs_by_chain(
  samples_m5[["kappa"]], "kappa",
  samples_m5[["alpha_f"]], "alpha_f"
)
```

### Trajectory lengths

```{r}
#| label: fig-m5-leapfrogs
#| fig-cap: "Model 5: Distribution of trajectory lengths by chain"

util$plot_num_leapfrogs_by_chain(diagnostics_m5)
```

### Adapted step sizes

```{r}
#| label: m5-step-sizes

cat("Adapted step sizes by chain:\n")
for (c in 1:4) {
  cat("  Chain", c, ":", diagnostics_m5$stepsize__[c,], "\n")
}
```

# Model 6: Heterogeneous Treatment Effect (Gap Interaction)

## Model Structure

Model 6 extends Model 5 by allowing the treatment effect to vary with gap. The key question: does AI help more (or less) for harder tasks?

**Latent structure (same as Model 5):**

-   `comfort_j ~ Normal(0, sigma_c)` (developer-level)
-   `task_burden_n ~ Normal(0, sigma_b)` (observation-level)
-   `gap_n = task_burden_n - comfort_j` (key derived quantity)

**Heterogeneous treatment effect:**

$$\mu_t = \alpha_t + \beta_{\text{gap}} \cdot \text{gap} + \beta_{\text{trt}} \cdot \text{ai} + \beta_{\text{gap_trt}} \cdot \text{gap} \cdot \text{ai}$$

The treatment effect is: $\beta_{\text{trt}} + \beta_{\text{gap_trt}} \cdot \text{gap}$

-   $\beta_{\text{trt}}$: treatment effect at gap = 0 (average task for average developer)
-   $\beta_{\text{gap_trt}}$: how effect changes per unit gap
    -   $> 0$: AI helps less (or hurts more) for harder tasks
    -   $< 0$: AI helps more for harder tasks

**Other outcomes (same as Model 5):**

-   `exposure ~ OrderedLogistic(lambda_e * comfort, cut_points_e)`
-   `resources ~ OrderedLogistic(lambda_r * gap, cut_points_r)`
-   `forecast ~ NegBinomial2(exp(alpha_f + gap), phi)`

## Prior Development

### Parameters for Model 6

| Parameter    | Prior                 | Interpretation                 |
|--------------|-----------------------|--------------------------------|
| sigma_c      | HalfNormal(0, 0.78)   | Developer comfort spread       |
| sigma_b      | HalfNormal(0, 0.39)   | Task burden spread             |
| sigma_t      | HalfNormal(0, 0.25)   | Completion time noise          |
| kappa        | HalfNormal(0, 0.10)   | Forecast overdispersion        |
| alpha_f      | Normal(log(17), 0.30) | Log expected forecast baseline |
| alpha_t      | Normal(log(90), 0.40) | Log median completion baseline |
| beta_gap     | Normal(1, 0.3)        | Gap → completion               |
| beta_trt     | Normal(0, 0.7)        | Treatment effect (at gap = 0)  |
| beta_gap_trt | Normal(0, 0.15)       | Gap × treatment interaction    |
| lambda_e     | Normal(1, 0.43)       | Comfort → exposure (+)         |
| lambda_r     | Normal(1, 0.43)       | Gap → resources (+)            |

**Prior calibration for beta_gap_trt:** Comparing a hard task (gap = +1) to an easy task (gap = -1), we would be shocked if the AI treatment effect differed by more than 80 percentage points. This corresponds to Normal(0, 0.15).

## Prior Predictive Check

```{r}
#| label: model6-prior-data

stan_data_m6_prior <- list(
  N = nrow(dat),
  J = length(unique(dat$dev_num)),
  dev_idx = dat$dev_num,
  ai_access = dat$ai_access,

  # Dirichlet hyperparameters (same as M5)
  rho_e = rep(1/5, 5),
  tau_e = 0.1,
  rho_r = rep(1/3, 3),
  tau_r = 0.2
)

cat("N observations:", stan_data_m6_prior$N, "\n")
cat("J developers:", stan_data_m6_prior$J, "\n")
```

```{r}
#| label: model6-prior-fit

fit_prior_m6 <- stan(
  file = "stan_programs/model6_prior.stan",
  data = stan_data_m6_prior,
  algorithm = "Fixed_param",
  iter = 1000,
  chains = 1,
  seed = 6543
)

samples_prior_m6 <- util$extract_expectand_vals(fit_prior_m6)
```

### Prior on beta_gap_trt (interaction term)

```{r}
#| label: fig-m6-prior-beta-gap-trt
#| fig-cap: "Model 6 prior: beta_gap_trt (gap x treatment interaction)"

util$plot_line_hist(samples_prior_m6$beta_gap_trt, -0.6, 0.6, 0.025,
                    xlab = "beta_gap_trt")
abline(v = 0, lty = 2, lwd = 2)
```

### Prior predictive: treatment effect heterogeneity

```{r}
#| label: fig-m6-prior-het-trt
#| fig-cap: "Model 6 prior predictive: treatment effect at different gap values"

par(mfrow = c(1, 3))

util$plot_line_hist(samples_prior_m6$pct_lift_low_gap, -100, 100, 5,
                    xlab = "% lift (easy task, gap = -1)")
abline(v = 0, lty = 2, lwd = 2)

util$plot_line_hist(samples_prior_m6$pct_lift, -100, 100, 5,
                    xlab = "% lift (avg task, gap = 0)")
abline(v = 0, lty = 2, lwd = 2)

util$plot_line_hist(samples_prior_m6$pct_lift_high_gap, -100, 100, 5,
                    xlab = "% lift (hard task, gap = +1)")
abline(v = 0, lty = 2, lwd = 2)
```

### Prior predictive: simulated completion times

```{r}
#| label: fig-m6-prior-y
#| fig-cap: "Model 6 prior predictive: completion time (minutes)"

util$plot_hist_quantiles(samples_prior_m6, 'y_sim', 0, 1500, 25,
                         xlab = "Completion time (minutes)")
```

### Prior predictive: log completion time

```{r}
#| label: fig-m6-prior-log-y
#| fig-cap: "Model 6 prior predictive: log completion time"

util$plot_hist_quantiles(samples_prior_m6, 'log_y_sim', 0, 10, 0.25,
                         xlab = "log(completion time)")
util$my_q(samples_prior_m6$`y_sim[100]`)
```

### Summary statistics

```{r}
#| label: m6-prior-summary

cat("Prior predictive summary:\n\n")

cat("beta_gap_trt (interaction):\n")
print(util$my_q(samples_prior_m6$beta_gap_trt))

cat("\nTreatment effect at gap = -1 (easy task):\n")
print(util$my_q(samples_prior_m6$pct_lift_low_gap))

cat("\nTreatment effect at gap = 0 (average task):\n")
print(util$my_q(samples_prior_m6$pct_lift))

cat("\nTreatment effect at gap = +1 (hard task):\n")
print(util$my_q(samples_prior_m6$pct_lift_high_gap))

cat("\nGap distribution (SD):\n")
print(util$my_q(samples_prior_m6$sd_gap))
```

## Model Fitting

```{r}
#| label: model6-fit-data

# Same data structure as Model 5
stan_data_m6 <- stan_data_m5

cat("N observations:", stan_data_m6$N, "\n")
cat("J developers:", stan_data_m6$J, "\n")
```

```{r}
#| label: model6-fit

fit_m6 <- stan(
  file = "stan_programs/model6.stan",
  data = stan_data_m6,
  chains = 4,
  iter = 4000,
  warmup = 2000,
  seed = 65432,
  control = list(adapt_delta = 0.8, max_treedepth = 10)
)
```

```{r}
#| label: model6-diagnostics

util$check_all_hmc_diagnostics(util$extract_hmc_diagnostics(fit_m6))
samples_m6 <- util$extract_expectand_vals(fit_m6)
base_samples_m6 <- util$filter_expectands(samples_m6,
  c('beta_gap', 'beta_trt', 'beta_gap_trt', 'alpha_f', 'alpha_t',
    'lambda_e', 'lambda_r',
    'sigma_c', 'sigma_b', 'sigma_t', 'kappa'))
util$check_all_expectand_diagnostics(base_samples_m6)
```

## Posterior Retrodictive Checks

### Log completion time

```{r}
#| label: fig-m6-retro-log-y
#| fig-cap: "Model 6 posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples_m6, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m6$y),
                         xlab = "log(completion time)")
```

### Forecast posterior predictive

```{r}
#| label: fig-m6-retro-forecast
#| fig-cap: "Model 6 posterior retrodictive: forecast time"

util$plot_hist_quantiles(samples_m6, 'forecast_pred', 0, 500, 25,
                         baseline_values = stan_data_m6$forecast,
                         xlab = "Forecast time (minutes)")
```

### Exposure distribution

```{r}
#| label: fig-m6-retro-exposure
#| fig-cap: "Model 6 posterior retrodictive: exposure distribution (observed cases)"

exposure_pred_obs_m6 <- samples_m6[paste0('exposure_pred[', obs_exposure_idx, ']')]
names(exposure_pred_obs_m6) <- paste0('exposure_pred_obs[', seq_along(obs_exposure_idx), ']')

util$plot_hist_quantiles(exposure_pred_obs_m6, 'exposure_pred_obs', 0.5, 5.5, 1,
                         baseline_values = stan_data_m6$exposure,
                         xlab = "Exposure (1-5)")
```

### Resources distribution

```{r}
#| label: fig-m6-retro-resources
#| fig-cap: "Model 6 posterior retrodictive: resources distribution (observed cases)"

resources_pred_obs_m6 <- samples_m6[paste0('resources_pred[', obs_resources_idx_m5, ']')]
names(resources_pred_obs_m6) <- paste0('resources_pred_obs[', seq_along(obs_resources_idx_m5), ']')

util$plot_hist_quantiles(resources_pred_obs_m6, 'resources_pred_obs', 0.5, 3.5, 1,
                         baseline_values = stan_data_m6$resources,
                         xlab = "Resources (1-3)")
```

## Posterior: Heterogeneous Treatment Effect

### Treatment effect at gap = 0 (average task)

```{r}
#| label: fig-m6-post-pct-lift
#| fig-cap: "Model 6 posterior: treatment effect at gap = 0 (% change)"

util$plot_line_hist(samples_m6$pct_lift, -60, 60, 2.5,
                    xlab = "% change in completion time (gap = 0)")
abline(v = 0, lty = 2, lwd = 2)

cat("Treatment effect at gap = 0 (% lift):\n")
print(util$my_q(samples_m6$pct_lift))
```

### Interaction term (beta_gap_trt)

```{r}
#| label: fig-m6-post-beta-gap-trt
#| fig-cap: "Model 6 posterior: beta_gap_trt (gap x treatment interaction)"

util$plot_expectand_pushforward(samples_m6[["beta_gap_trt"]], 25,
                                display_name = "beta_gap_trt", flim = c(-0.6, 0.6))
abline(v = 0, lty = 2, lwd = 2)

cat("beta_gap_trt (interaction):\n")
print(util$my_q(samples_m6$beta_gap_trt))
```

### Treatment effect across gap values

```{r}
#| label: fig-m6-post-het-trt
#| fig-cap: "Model 6 posterior: treatment effect at different gap values"

par(mfrow = c(1,1))

util$plot_line_hist(samples_m6$pct_lift_low_gap, -80, 80, 4,
                    xlab = "% lift (easy task, gap = -1)")
abline(v = 0, lty = 2, lwd = 2)

util$plot_line_hist(samples_m6$pct_lift, -80, 80, 4,
                    xlab = "% lift (avg task, gap = 0)")
abline(v = 0, lty = 2, lwd = 2)

util$plot_line_hist(samples_m6$pct_lift_high_gap, -80, 80, 4,
                    xlab = "% lift (hard task, gap = +1)")
abline(v = 0, lty = 2, lwd = 2)
```

```{r}
#| label: m6-het-trt-summary

cat("Treatment effect heterogeneity:\n\n")

cat("Easy task (gap = -1):\n")
print(util$my_q(samples_m6$pct_lift_low_gap))

cat("\nAverage task (gap = 0):\n")
print(util$my_q(samples_m6$pct_lift))

cat("\nHard task (gap = +1):\n")
print(util$my_q(samples_m6$pct_lift_high_gap))

cat("\nDifference (hard - easy):\n")
print(util$my_q(samples_m6$pct_lift_high_gap - samples_m6$pct_lift_low_gap))
```

### Parameter summaries

```{r}
#| label: m6-param-summary

print(fit_m6, pars = c("sigma_c", "sigma_b", "sigma_t", "kappa",
                        "alpha_f", "alpha_t",
                        "beta_gap", "beta_trt", "beta_gap_trt",
                        "lambda_e", "lambda_r"))
```

### Prior vs Posterior comparisons

```{r}
#| label: fig-m6-prior-post-sigma
#| fig-cap: "Model 6: Prior (teal) vs Posterior for dispersion parameters"
#| fig-height: 8

par(mfrow = c(2, 2))

# sigma_c
util$plot_expectand_pushforward(samples_m6[["sigma_c"]], 25,
                                display_name = "sigma_c", flim = c(0, 1.5))
xs <- seq(0, 1.5, 0.01)
lines(xs, 2 * dnorm(xs, 0, 0.78), lwd = 2, col = c_light_teal)

# sigma_b
util$plot_expectand_pushforward(samples_m6[["sigma_b"]], 25,
                                display_name = "sigma_b", flim = c(0, 1))
xs <- seq(0, 1, 0.01)
lines(xs, 2 * dnorm(xs, 0, 0.39), lwd = 2, col = c_light_teal)

# sigma_t
util$plot_expectand_pushforward(samples_m6[["sigma_t"]], 25,
                                display_name = "sigma_t", flim = c(0, 0.8))
xs <- seq(0, 0.8, 0.01)
lines(xs, 2 * dnorm(xs, 0, 0.25), lwd = 2, col = c_light_teal)

# kappa
util$plot_expectand_pushforward(samples_m6[["kappa"]], 25,
                                display_name = "kappa", flim = c(0, 0.4))
xs <- seq(0, 0.4, 0.005)
lines(xs, 2 * dnorm(xs, 0, 0.10), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m6-prior-post-location
#| fig-cap: "Model 6: Prior (teal) vs Posterior for location parameters"

par(mfrow = c(1, 2))

# alpha_f
util$plot_expectand_pushforward(samples_m6[["alpha_f"]], 25,
                                display_name = "alpha_f", flim = c(1.5, 4.5))
xs <- seq(1.5, 4.5, 0.01)
lines(xs, dnorm(xs, log(17), 0.30), lwd = 2, col = c_light_teal)

# alpha_t
util$plot_expectand_pushforward(samples_m6[["alpha_t"]], 25,
                                display_name = "alpha_t", flim = c(3.5, 5.5))
xs <- seq(3.5, 5.5, 0.01)
lines(xs, dnorm(xs, log(90), 0.40), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m6-prior-post-beta
#| fig-cap: "Model 6: Prior (teal) vs Posterior for treatment/gap coefficients"

par(mfrow = c(1, 3))

# beta_gap
util$plot_expectand_pushforward(samples_m6[["beta_gap"]], 25,
                                display_name = "beta_gap", flim = c(0, 2))
xs <- seq(0, 2, 0.01)
lines(xs, dnorm(xs, 1, 0.3), lwd = 2, col = c_light_teal)

# beta_trt
util$plot_expectand_pushforward(samples_m6[["beta_trt"]], 25,
                                display_name = "beta_trt", flim = c(-1.5, 1.5))
xs <- seq(-1.5, 1.5, 0.01)
lines(xs, dnorm(xs, 0, 0.7), lwd = 2, col = c_light_teal)

# beta_gap_trt (the new interaction term)
util$plot_expectand_pushforward(samples_m6[["beta_gap_trt"]], 25,
                                display_name = "beta_gap_trt", flim = c(-0.6, 0.6))
xs <- seq(-0.6, 0.6, 0.01)
lines(xs, dnorm(xs, 0, 0.15), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m6-prior-post-lambda
#| fig-cap: "Model 6: Prior (teal) vs Posterior for ordinal coefficients"

par(mfrow = c(1, 2))

# lambda_e
util$plot_expectand_pushforward(samples_m6[["lambda_e"]], 25,
                                display_name = "lambda_e", flim = c(-0.5, 2.5))
xs <- seq(-0.5, 2.5, 0.01)
lines(xs, dnorm(xs, 1, 0.43), lwd = 2, col = c_light_teal)

# lambda_r
util$plot_expectand_pushforward(samples_m6[["lambda_r"]], 25,
                                display_name = "lambda_r", flim = c(-0.5, 2.5))
xs <- seq(-0.5, 2.5, 0.01)
lines(xs, dnorm(xs, 1, 0.43), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m6-prior-post-latent
#| fig-cap: "Model 6: Prior (teal) vs Posterior for example latent variables"

par(mfrow = c(1, 2))

# comfort[1] - example developer comfort
# Prior: Normal(0, sigma_c) where sigma_c ~ HalfNormal(0, 0.78)
# Marginal prior is approximately Normal(0, 0.78) in practice
util$plot_expectand_pushforward(samples_m6[["comfort[1]"]], 25,
                                display_name = "comfort[1]", flim = c(-2, 2))
xs <- seq(-2, 2, 0.01)
lines(xs, dnorm(xs, 0, 0.78), lwd = 2, col = c_light_teal)

# task_burden[1] - example task burden
# Prior: Normal(0, sigma_b) where sigma_b ~ HalfNormal(0, 0.39)
util$plot_expectand_pushforward(samples_m6[["task_burden[1]"]], 25,
                                display_name = "task_burden[1]", flim = c(-1.5, 2))
xs <- seq(-1.5, 1.5, 0.01)
lines(xs, dnorm(xs, 0, 0.39), lwd = 2, col = c_light_teal)
```

### Individual developer completion time checks

Select 4 developers with low, mid, and high mean completion times (minimum 10 observations each).

```{r}
#| label: m6-select-devs

# Compute mean completion time and count per developer
dev_mean_y <- sapply(1:stan_data_m6$J, function(j) {
  idx <- which(stan_data_m6$dev_idx == j)
  mean(stan_data_m6$y[idx])
})

dev_n_obs <- sapply(1:stan_data_m6$J, function(j) {
  sum(stan_data_m6$dev_idx == j)
})

# Filter to developers with at least 10 observations
eligible_devs <- which(dev_n_obs >= 10)
cat("Developers with >= 10 observations:", length(eligible_devs), "of", stan_data_m6$J, "\n\n")

# Select developers at different quantiles among eligible
dev_order <- eligible_devs[order(dev_mean_y[eligible_devs])]
n_eligible <- length(dev_order)
selected_devs <- dev_order[c(
  1,                            # lowest
  round(n_eligible / 3),        # lower-mid
  round(2 * n_eligible / 3),    # upper-mid
  n_eligible                    # highest
)]

cat("Selected developers and their mean completion times:\n")
for (d in selected_devs) {
  cat("  Developer", d, ": n =", dev_n_obs[d], ", mean =", round(dev_mean_y[d], 1), "min\n")
}
```

```{r}
#| label: fig-m6-dev-y-checks
#| fig-cap: "Model 6: completion time posterior predictive by developer"
#| fig-height: 10

par(mfrow = c(1,1))

for (d in selected_devs) {
  idx <- which(stan_data_m6$dev_idx == d)

  # Extract y_pred for this developer's observations
  dev_y_pred <- samples_m6[paste0('y_pred[', idx, ']')]
  names(dev_y_pred) <- paste0('y_pred_dev[', seq_along(idx), ']')

  util$plot_hist_quantiles(dev_y_pred, 'y_pred_dev', 0, 800, 25,
                           baseline_values = stan_data_m6$y[idx],
                           xlab = "Completion time (minutes)")
  title(paste0("Developer ", d, " (n=", length(idx), ", mean=",
               round(dev_mean_y[d], 0), " min)"), line = 1)
}
```

### Treatment effect by developer comfort

Compute average treatment effect for each developer and examine relationship with comfort.

```{r}
#| label: m6-trt-by-comfort

n_draws <- length(samples_m6$beta_trt)

# For each posterior draw, compute average treatment effect per developer
# trt_effect_n = beta_trt + beta_gap_trt * gap_n
# where gap_n = task_burden_n - comfort_j

# Extract posterior samples
beta_trt_draws <- samples_m6$beta_trt
beta_gap_trt_draws <- samples_m6$beta_gap_trt

# Get comfort and task_burden samples
comfort_samples <- lapply(1:stan_data_m6$J, function(j) {
  samples_m6[[paste0("comfort[", j, "]")]]
})

task_burden_samples <- lapply(1:stan_data_m6$N, function(n) {
  samples_m6[[paste0("task_burden[", n, "]")]]
})

# Compute average pct_lift per developer for each draw
avg_pct_lift_dev <- matrix(NA, nrow = n_draws, ncol = stan_data_m6$J)

for (j in 1:stan_data_m6$J) {
  idx <- which(stan_data_m6$dev_idx == j)

  # For each draw, compute mean treatment effect across this developer's tasks
  for (s in 1:n_draws) {
    gaps <- sapply(idx, function(n) {
      task_burden_samples[[n]][s] - comfort_samples[[j]][s]
    })
    trt_effects <- beta_trt_draws[s] + beta_gap_trt_draws[s] * gaps
    avg_pct_lift_dev[s, j] <- mean((exp(trt_effects) - 1) * 100)
  }
}

# Compute posterior mean comfort per developer
mean_comfort_dev <- sapply(1:stan_data_m6$J, function(j) {
  mean(comfort_samples[[j]])
})
```

```{r}
#| label: fig-m6-trt-vs-comfort
#| fig-cap: "Model 6: average treatment effect vs developer comfort"

# Posterior mean of average pct_lift per developer
mean_avg_pct_lift_dev <- colMeans(avg_pct_lift_dev)
sd_avg_pct_lift_dev <- apply(avg_pct_lift_dev, 2, sd)

plot(mean_comfort_dev, mean_avg_pct_lift_dev, pch = 19,
     xlab = "Developer comfort (posterior mean)",
     ylab = "Avg treatment effect (% lift)",
     main = "Treatment effect vs comfort by developer")
segments(mean_comfort_dev, mean_avg_pct_lift_dev - 2*sd_avg_pct_lift_dev,
         mean_comfort_dev, mean_avg_pct_lift_dev + 2*sd_avg_pct_lift_dev,
         col = "gray")
abline(h = 0, lty = 2)

# Add regression line
fit_line <- lm(mean_avg_pct_lift_dev ~ mean_comfort_dev)
abline(fit_line, col = "red", lwd = 2)
```

```{r}
#| label: fig-m6-trt-by-comfort-bin
#| fig-cap: "Model 6: treatment effect distribution by comfort tercile"

# Bin developers by comfort terciles
comfort_terciles <- cut(mean_comfort_dev,
                        breaks = quantile(mean_comfort_dev, c(0, 1/3, 2/3, 1)),
                        labels = c("Low comfort", "Mid comfort", "High comfort"),
                        include.lowest = TRUE)

par(mfrow = c(1, 3))

for (tercile in levels(comfort_terciles)) {
  dev_in_tercile <- which(comfort_terciles == tercile)

  # Pool all posterior draws of avg_pct_lift for developers in this tercile
  pooled_pct_lift <- as.vector(avg_pct_lift_dev[, dev_in_tercile])

  util$plot_line_hist(pooled_pct_lift, -80, 80, 4,
                      xlab = "Avg % lift")
  abline(v = 0, lty = 2, lwd = 2)
  title(paste0(tercile, " (n=", length(dev_in_tercile), " devs)"), line = 1)
}
```

```{r}
#| label: m6-trt-by-comfort-summary

cat("Treatment effect by comfort tercile:\n\n")

for (tercile in levels(comfort_terciles)) {
  dev_in_tercile <- which(comfort_terciles == tercile)
  pooled_pct_lift <- as.vector(avg_pct_lift_dev[, dev_in_tercile])

  cat(tercile, ":\n")
  print(util$my_q(pooled_pct_lift))
  cat("\n")
}
```

### Completion time and treatment effect by gap

Bin observations by inferred gap (task_burden - comfort) and examine completion time fit and treatment effects.

```{r}
#| label: m6-gap-bins

# Compute posterior mean gap per observation
mean_gap <- sapply(1:stan_data_m6$N, function(n) {
  j <- stan_data_m6$dev_idx[n]
  mean(task_burden_samples[[n]] - comfort_samples[[j]])
})

# Bin observations by gap terciles
gap_terciles <- cut(mean_gap,
                    breaks = quantile(mean_gap, c(0, 1/3, 2/3, 1)),
                    labels = c("Low gap (easy)", "Mid gap", "High gap (hard)"),
                    include.lowest = TRUE)

cat("Observations by gap tercile:\n")
print(table(gap_terciles))
```

```{r}
#| label: fig-m6-y-by-gap
#| fig-cap: "Model 6: completion time posterior predictive by gap tercile"
#| fig-height: 4

par(mfrow = c(1, 1))

for (tercile in levels(gap_terciles)) {
  idx <- which(gap_terciles == tercile)

  # Extract y_pred for observations in this tercile
  gap_y_pred <- samples_m6[paste0('y_pred[', idx, ']')]
  names(gap_y_pred) <- paste0('y_pred_gap[', seq_along(idx), ']')

  util$plot_hist_quantiles(gap_y_pred, 'y_pred_gap', 0, 800, 25,
                           baseline_values = stan_data_m6$y[idx],
                           xlab = "Completion time (minutes)")
  title(paste0(tercile, " (n=", length(idx), ")"), line = 1)
}
```

```{r}
#| label: m6-trt-by-gap

# Compute treatment effect for each observation at each posterior draw
# trt_effect_n = beta_trt + beta_gap_trt * gap_n

pct_lift_obs <- matrix(NA, nrow = n_draws, ncol = stan_data_m6$N)

for (n in 1:stan_data_m6$N) {
  j <- stan_data_m6$dev_idx[n]
  for (s in 1:n_draws) {
    gap <- task_burden_samples[[n]][s] - comfort_samples[[j]][s]
    trt_effect <- beta_trt_draws[s] + beta_gap_trt_draws[s] * gap
    pct_lift_obs[s, n] <- (exp(trt_effect) - 1) * 100
  }
}
```

```{r}
#| label: fig-m6-trt-by-gap
#| fig-cap: "Model 6: treatment effect distribution by gap tercile"

par(mfrow = c(1, 1))

for (tercile in levels(gap_terciles)) {
  idx <- which(gap_terciles == tercile)

  # Pool all posterior draws for observations in this tercile
  pooled_pct_lift <- as.vector(pct_lift_obs[, idx])

  util$plot_line_hist(pooled_pct_lift, -80, 80, 4,
                      xlab = "% lift")
  abline(v = 0, lty = 2, lwd = 2)
  title(paste0(tercile, " (n=", length(idx), " obs)"), line = 1)
}
```

```{r}
#| label: m6-trt-by-gap-summary

cat("Treatment effect by gap tercile:\n\n")

for (tercile in levels(gap_terciles)) {
  idx <- which(gap_terciles == tercile)
  pooled_pct_lift <- as.vector(pct_lift_obs[, idx])

  cat(tercile, ":\n")
  print(util$my_q(pooled_pct_lift))
  cat("\n")
}
```

### Compare treatment effects across models

Note: Model 6 has heterogeneous treatment effects; this shows the effect at gap = 0.

```{r}
#| label: fig-m6-compare-trt
#| fig-cap: "Treatment effect comparison: Models 1-6 (M6 at gap = 0)"

util$plot_line_hist(samples_m1$pct_lift, -60, 60, 2.5,
                    xlab = "% change in completion time",
                    col = util$c_light)
util$plot_line_hist(samples_m2$pct_lift, -60, 60, 2.5,
                    col = util$c_mid, add = TRUE)
util$plot_line_hist(samples_m3$pct_lift, -60, 60, 2.5,
                    col = util$c_dark, add = TRUE)
util$plot_line_hist(samples_m4$pct_lift, -60, 60, 2.5,
                    col = util$c_mid_highlight, add = TRUE)
util$plot_line_hist(samples_m5$pct_lift, -60, 60, 2.5,
                    col = util$c_dark_highlight, add = TRUE)
util$plot_line_hist(samples_m6$pct_lift, -60, 60, 2.5,
                    col = "purple", add = TRUE)

abline(v = 0, lty = 2, lwd = 2)

legend("topright", c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5", "Model 6 (gap=0)"),
       fill = c(util$c_light, util$c_mid, util$c_dark, util$c_mid_highlight, util$c_dark_highlight, "purple"))
```

### Compare M5 vs M6: Log Completion Time Posterior Predictive

```{r}
#| label: fig-m5-m6-compare-log-y
#| fig-cap: "Log completion time posterior predictive: Model 5 (top) vs Model 6 (bottom)"
#| fig-height: 8

par(mfrow = c(2, 1))

# Model 5
util$plot_hist_quantiles(samples_m5, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m5$y),
                         xlab = "log(completion time)")
title("Model 5 (homogeneous treatment)", line = 1)

# Model 6
util$plot_hist_quantiles(samples_m6, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m6$y),
                         xlab = "log(completion time)")
title("Model 6 (heterogeneous treatment)", line = 1)
```

## Appendix: Investigating Diagnostics in Model 6

```{r}
#| label: m6-diagnostics-extract

diagnostics_m6 <- util$extract_hmc_diagnostics(fit_m6)
```

### Key parameter posteriors by chain

```{r}
#| label: fig-m6-beta-gap-trt-by-chain
#| fig-cap: "Model 6: beta_gap_trt posterior by chain"

util$plot_pairs_by_chain(
  samples_m6[["beta_gap_trt"]], "beta_gap_trt",
  samples_m6[["beta_trt"]], "beta_trt"
)

util$plot_pairs_by_chain(
  samples_m6[["beta_gap_trt"]], "beta_gap_trt",
  samples_m6[["beta_gap"]], "beta_gap"
)
```

### Divergence locations

Where are divergences occurring?

```{r}
#| label: fig-m6-div-pairs
#| fig-cap: "Model 6: divergence locations"
#| fig-width: 10
#| fig-height: 8

util$plot_div_pairs(
  x_names = c("sigma_t"),
  y_names = c("sigma_c", "sigma_b", "alpha_f", "kappa", "beta_gap",
               "beta_trt", "beta_gap_trt", "alpha_t"),
  expectand_vals_list = samples_m6,
  diagnostics = diagnostics_m6,
  plot_mode = 0
)
```

### Developer comfort and task burden posteriors

```{r}
#| label: fig-m6-dev-comfort-burden
#| fig-cap: "Model 6: developer-specific comfort and task burden posteriors"
par(mfrow=c(1,2))

for (dev in c(1, 5, 10, 15)) {

  dev_idx <- which(stan_data_m6$dev_idx == dev)

  util$plot_expectand_pushforward(samples_m6[[paste0('comfort[', dev, ']')]], 25, flim=c(-1,1))
  abline(v=0)
  title(paste("Developer", dev, "comfort"))

  task_burden_means <- sapply(dev_idx, function(j) {
    mean(samples_m6[[paste0("task_burden[", j, "]")]])
  })

  task_burden_sds <- sapply(dev_idx, function(j) {
    sd(samples_m6[[paste0("task_burden[", j, "]")]])
  })

  ord <- order(task_burden_means)

  plot(1:length(dev_idx), task_burden_means[ord], pch = 19,
       xlab = "Task (ordered by mean task burden)",
       ylab = "Task Burden",
       ylim = c(-2, 2),
       main = paste("Developer", dev, "task burdens (±2 SD)"))
  segments(1:length(dev_idx), task_burden_means[ord] - 2*task_burden_sds[ord],
           1:length(dev_idx), task_burden_means[ord] + 2*task_burden_sds[ord])
  abline(h = 0, lty = 2)
}
```

### Chain mixing for key parameters

```{r}
#| label: fig-m6-pairs-chain
#| fig-cap: "Model 6: chain mixing for key parameters"

util$plot_pairs_by_chain(
  samples_m6[["sigma_b"]], "sigma_b",
  samples_m6[["beta_gap"]], "beta_gap"
)

util$plot_pairs_by_chain(
  samples_m6[["sigma_c"]], "sigma_c",
  samples_m6[["beta_gap"]], "beta_gap"
)

util$plot_pairs_by_chain(
  samples_m6[["beta_trt"]], "beta_trt",
  samples_m6[["beta_gap_trt"]], "beta_gap_trt"
)
```

### Trajectory lengths by chain

```{r}
#| label: fig-m6-leapfrogs
#| fig-cap: "Model 6: trajectory lengths by chain"

util$plot_num_leapfrogs_by_chain(diagnostics_m6)
```

# Exploratory: Within-Developer Relationships

Before building Model 7, we validate the assumed within-developer relationships:

1.  Higher exposure → faster completion (within developer)
2.  Higher resources → slower completion (within developer)

If these hold, it supports the model structure where exposure and resources are both informed by task-level burden.

```{r}
#| label: within-dev-setup

# Prepare data with exposure and resources
dat_explore <- dat[!is.na(dat$total_time), ]
dat_explore$log_y <- log(dat_explore$total_time)
dat_explore$exposure <- dat_explore$prior_task_exposure_1_to_5
dat_explore$resources <- dat_explore$external_resource_needs_1_to_3
dat_explore$resources[dat_explore$resources == 5] <- 3  # recode as before
```

## Within-developer correlations

For each developer with at least 5 observations, compute the correlation between exposure and log completion time.

```{r}
#| label: fig-within-dev-cor-exposure
#| fig-cap: "Within-developer correlations: exposure vs log(completion time)"

# Get developers with enough observations for exposure
dev_counts_exp <- tapply(!is.na(dat_explore$exposure), dat_explore$dev_num, sum)
devs_with_exposure <- as.integer(names(dev_counts_exp[dev_counts_exp >= 5]))

# Compute within-developer correlations
within_cor_exposure <- sapply(devs_with_exposure, function(d) {
  idx <- dat_explore$dev_num == d & !is.na(dat_explore$exposure)
  if (sum(idx) >= 5) {
    cor(dat_explore$exposure[idx], dat_explore$log_y[idx])
  } else {
    NA
  }
})
within_cor_exposure <- within_cor_exposure[!is.na(within_cor_exposure)]

# Histogram
hist(within_cor_exposure, breaks = 20, col = "steelblue", border = "white",
     main = "Within-developer correlation: exposure vs log(completion)",
     xlab = "Correlation",
     sub = "Negative values support: high exposure → faster completion")
abline(v = 0, lty = 2, lwd = 2)
abline(v = median(within_cor_exposure), col = "red", lwd = 2)

cat("Median within-developer correlation:", round(median(within_cor_exposure), 3), "\n")
cat("Proportion negative:", round(mean(within_cor_exposure < 0), 2), "\n")
```

```{r}
#| label: fig-within-dev-cor-resources
#| fig-cap: "Within-developer correlations: resources vs log(completion time)"

# Get developers with enough observations for resources
dev_counts_res <- tapply(!is.na(dat_explore$resources), dat_explore$dev_num, sum)
devs_with_resources <- as.integer(names(dev_counts_res[dev_counts_res >= 5]))

# Compute within-developer correlations
within_cor_resources <- sapply(devs_with_resources, function(d) {
  idx <- dat_explore$dev_num == d & !is.na(dat_explore$resources)
  if (sum(idx) >= 5) {
    cor(dat_explore$resources[idx], dat_explore$log_y[idx])
  } else {
    NA
  }
})
within_cor_resources <- within_cor_resources[!is.na(within_cor_resources)]

# Histogram
hist(within_cor_resources, breaks = 20, col = "coral", border = "white",
     main = "Within-developer correlation: resources vs log(completion)",
     xlab = "Correlation",
     sub = "Positive values support: high resources → slower completion")
abline(v = 0, lty = 2, lwd = 2)
abline(v = median(within_cor_resources), col = "red", lwd = 2)

cat("Median within-developer correlation:", round(median(within_cor_resources), 3), "\n")
cat("Proportion positive:", round(mean(within_cor_resources > 0), 2), "\n")
```

## Developer-demeaned scatterplots

Remove between-developer variation to isolate within-developer relationships.

```{r}
#| label: fig-demeaned-exposure
#| fig-cap: "Within-developer: exposure vs log(completion time) - both demeaned"

# Demean within developers (exposure)
dat_exp <- dat_explore[!is.na(dat_explore$exposure), ]
dev_means_log_y <- tapply(dat_exp$log_y, dat_exp$dev_num, mean)
dev_means_exp <- tapply(dat_exp$exposure, dat_exp$dev_num, mean)

dat_exp$log_y_demeaned <- dat_exp$log_y - dev_means_log_y[as.character(dat_exp$dev_num)]
dat_exp$exposure_demeaned <- dat_exp$exposure - dev_means_exp[as.character(dat_exp$dev_num)]

# Jittered scatterplot
plot(jitter(dat_exp$exposure_demeaned, amount = 0.1), dat_exp$log_y_demeaned,
     pch = 19, col = rgb(0, 0, 0, 0.3), cex = 0.8,
     xlab = "Exposure (demeaned within developer)",
     ylab = "Log completion time (demeaned within developer)",
     main = "Within-developer: exposure vs completion time")

# Add regression line
fit_exp <- lm(log_y_demeaned ~ exposure_demeaned, data = dat_exp)
abline(fit_exp, col = "red", lwd = 2)
abline(h = 0, lty = 2)

cat("Within-developer slope (exposure → log completion):",
    round(coef(fit_exp)[2], 4), "\n")
cat("Expected: negative (higher exposure → faster)\n")
```

```{r}
#| label: fig-demeaned-resources
#| fig-cap: "Within-developer: resources vs log(completion time) - both demeaned"

# Demean within developers (resources)
dat_res <- dat_explore[!is.na(dat_explore$resources), ]
dev_means_log_y_r <- tapply(dat_res$log_y, dat_res$dev_num, mean)
dev_means_res <- tapply(dat_res$resources, dat_res$dev_num, mean)

dat_res$log_y_demeaned <- dat_res$log_y - dev_means_log_y_r[as.character(dat_res$dev_num)]
dat_res$resources_demeaned <- dat_res$resources - dev_means_res[as.character(dat_res$dev_num)]

# Jittered scatterplot
plot(jitter(dat_res$resources_demeaned, amount = 0.1), dat_res$log_y_demeaned,
     pch = 19, col = rgb(0, 0, 0, 0.3), cex = 0.8,
     xlab = "Resources (demeaned within developer)",
     ylab = "Log completion time (demeaned within developer)",
     main = "Within-developer: resources vs completion time")

# Add regression line
fit_res <- lm(log_y_demeaned ~ resources_demeaned, data = dat_res)
abline(fit_res, col = "red", lwd = 2)
abline(h = 0, lty = 2)

cat("Within-developer slope (resources → log completion):",
    round(coef(fit_res)[2], 4), "\n")
cat("Expected: positive (higher resources → slower)\n")
```

## Mean completion time by ordinal level (within-developer standardized)

```{r}
#| label: fig-exposure-bars
#| fig-cap: "Within-developer standardized completion time by exposure level"

# Compute within-developer z-scores
dat_exp$z_log_y <- (dat_exp$log_y - dev_means_log_y[as.character(dat_exp$dev_num)]) /
                   tapply(dat_exp$log_y, dat_exp$dev_num, sd)[as.character(dat_exp$dev_num)]

# Handle developers with zero variance (only one observation after filtering)
dat_exp$z_log_y[!is.finite(dat_exp$z_log_y)] <- NA

# Mean z-score by exposure level
mean_z_by_exposure <- tapply(dat_exp$z_log_y, dat_exp$exposure, mean, na.rm = TRUE)
n_by_exposure <- tapply(dat_exp$z_log_y, dat_exp$exposure, function(x) sum(!is.na(x)))

barplot(mean_z_by_exposure, names.arg = names(mean_z_by_exposure),
        col = "steelblue", border = "white",
        xlab = "Exposure level", ylab = "Mean within-developer z-score",
        main = "Completion time by exposure (within-developer standardized)",
        sub = "Negative bars = faster than developer's average")
abline(h = 0, lty = 2, lwd = 2)

cat("Mean z-score by exposure level:\n")
print(round(mean_z_by_exposure, 3))
cat("\nN by exposure level:\n")
print(n_by_exposure)
```

```{r}
#| label: fig-resources-bars
#| fig-cap: "Within-developer standardized completion time by resources level"

# Compute within-developer z-scores
dat_res$z_log_y <- (dat_res$log_y - dev_means_log_y_r[as.character(dat_res$dev_num)]) /
                   tapply(dat_res$log_y, dat_res$dev_num, sd)[as.character(dat_res$dev_num)]

dat_res$z_log_y[!is.finite(dat_res$z_log_y)] <- NA

# Mean z-score by resources level
mean_z_by_resources <- tapply(dat_res$z_log_y, dat_res$resources, mean, na.rm = TRUE)
n_by_resources <- tapply(dat_res$z_log_y, dat_res$resources, function(x) sum(!is.na(x)))

barplot(mean_z_by_resources, names.arg = names(mean_z_by_resources),
        col = "coral", border = "white",
        xlab = "Resources level", ylab = "Mean within-developer z-score",
        main = "Completion time by resources (within-developer standardized)",
        sub = "Positive bars = slower than developer's average")
abline(h = 0, lty = 2, lwd = 2)

cat("Mean z-score by resources level:\n")
print(round(mean_z_by_resources, 3))
cat("\nN by resources level:\n")
print(n_by_resources)
```

## Individual developer facets

```{r}
#| label: fig-facet-exposure
#| fig-cap: "Exposure vs log(completion time) for developers with most observations"
#| fig-height: 6

# Select top 6 developers by number of exposure observations
n_exp_by_dev <- tapply(!is.na(dat_explore$exposure), dat_explore$dev_num, sum)
top_devs <- as.integer(names(sort(n_exp_by_dev, decreasing = TRUE)[1:6]))

par(mfrow = c(2, 3))
for (d in top_devs) {
  idx <- dat_explore$dev_num == d & !is.na(dat_explore$exposure)
  plot(jitter(dat_explore$exposure[idx], amount = 0.15), dat_explore$log_y[idx],
       pch = 19, col = rgb(0.2, 0.4, 0.6, 0.7),
       xlab = "Exposure", ylab = "Log completion time",
       main = paste0("Developer ", d, " (n=", sum(idx), ")"),
       xlim = c(0.5, 5.5))

  if (sum(idx) >= 3) {
    fit <- lm(log_y ~ exposure, data = dat_explore[idx, ])
    abline(fit, col = "red", lwd = 2)
  }
}
```

```{r}
#| label: fig-facet-resources
#| fig-cap: "Resources vs log(completion time) for developers with most observations"
#| fig-height: 6

# Select top 6 developers by number of resources observations
n_res_by_dev <- tapply(!is.na(dat_explore$resources), dat_explore$dev_num, sum)
top_devs_res <- as.integer(names(sort(n_res_by_dev, decreasing = TRUE)[1:6]))

par(mfrow = c(2, 3))
for (d in top_devs_res) {
  idx <- dat_explore$dev_num == d & !is.na(dat_explore$resources)
  plot(jitter(dat_explore$resources[idx], amount = 0.15), dat_explore$log_y[idx],
       pch = 19, col = rgb(0.8, 0.4, 0.3, 0.7),
       xlab = "Resources", ylab = "Log completion time",
       main = paste0("Developer ", d, " (n=", sum(idx), ")"),
       xlim = c(0.5, 3.5))

  if (sum(idx) >= 3) {
    fit <- lm(log_y ~ resources, data = dat_explore[idx, ])
    abline(fit, col = "red", lwd = 2)
  }
}
```

## Summary

```{r}
#| label: within-dev-summary

cat("=== WITHIN-DEVELOPER RELATIONSHIP SUMMARY ===\n\n")

cat("EXPOSURE → COMPLETION TIME:\n")
cat("  Median within-dev correlation:", round(median(within_cor_exposure), 3), "\n")
cat("  Proportion negative:", round(mean(within_cor_exposure < 0), 2), "\n")
cat("  Pooled within-dev slope:", round(coef(fit_exp)[2], 4), "\n")
cat("  Expected: NEGATIVE (high exposure → fast completion)\n\n")

cat("RESOURCES → COMPLETION TIME:\n")
cat("  Median within-dev correlation:", round(median(within_cor_resources), 3), "\n")
cat("  Proportion positive:", round(mean(within_cor_resources > 0), 2), "\n")
cat("  Pooled within-dev slope:", round(coef(fit_res)[2], 4), "\n")
cat("  Expected: POSITIVE (high resources → slow completion)\n\n")

cat("If both expectations hold, it supports:\n")
cat("  - exposure ~ f(-burden)\n")
cat("  - resources ~ f(+burden)\n")
cat("where burden is a task-level latent variable.\n")
```

# Model 7: Hierarchical Factor Model

## Model Structure

Model 7 restructures the latent variables to better use exposure and resources for identification:

**Latent structure:**

-   $\mu_j \sim \text{Normal}(0, \sigma_\mu)$ — developer mean (where developer j typically sits)
-   $\delta_n \sim \text{Normal}(0, \sigma_\delta)$ — task deviation (how much harder/easier than typical for this developer)
-   $\eta_n = \mu_j + \delta_n$ — total latent variable

**Outcomes:**

-   `forecast ~ NegBinomial2(exp(alpha_f + eta), phi)` — loads on eta (coef = 1 for identification)
-   `exposure ~ OrderedLogistic(-lambda_e * delta, cuts_e)` — loads on delta (negative: high delta = hard task = low exposure)
-   `resources ~ OrderedLogistic(lambda_r * delta, cuts_r)` — loads on delta (positive: high delta = hard task = high resources)
-   `y ~ Lognormal(alpha_t + beta_eta * eta + beta_trt * ai + beta_eta_trt * eta * ai, sigma_t)` — loads on eta with heterogeneous treatment

**Identification:**

-   Forecast identifies eta = mu + delta (coefficient fixed to 1)
-   Exposure and resources identify delta (task-level component)
-   Together: we can separate mu from delta

**Key difference from Model 6:** Exposure and resources now load on delta (task deviation) rather than on comfort or gap. This means they inform "how unusual is this task for this developer" rather than developer-level properties.

## Priors

| Parameter    | Prior                 | Interpretation                 |
|--------------|-----------------------|--------------------------------|
| sigma_mu     | HalfNormal(0, 0.78)   | Developer mean spread          |
| sigma_delta  | HalfNormal(0, 0.39)   | Task deviation spread          |
| sigma_t      | HalfNormal(0, 0.25)   | Completion time noise          |
| kappa        | HalfNormal(0, 0.10)   | Forecast overdispersion        |
| alpha_f      | Normal(log(17), 0.30) | Log expected forecast baseline |
| alpha_t      | Normal(log(90), 0.40) | Log median completion baseline |
| beta_eta     | Normal(1, 0.3)        | eta -\> completion             |
| beta_trt     | Normal(0, 0.7)        | Treatment effect at eta = 0    |
| beta_eta_trt | Normal(0, 0.15)       | eta x treatment interaction    |
| lambda_e     | Normal(1, 0.43)       | delta -\> exposure             |
| lambda_r     | Normal(1, 0.43)       | delta -\> resources            |

## Prior Predictive Checks

```{r}
#| label: m7-prior-data

stan_data_m7_prior <- list(
  N = stan_data_m6$N,
  J = stan_data_m6$J,
  dev_idx = stan_data_m6$dev_idx,
  ai_access = stan_data_m6$ai_access,

  # Dirichlet hyperparameters for exposure (K=5)
  rho_e = rep(1/5, 5),
  tau_e = 0.1,

  # Dirichlet hyperparameters for resources (K=3)
  rho_r = rep(1/3, 3),
  tau_r = 0.2
)
```

```{r}
#| label: m7-prior-fit

fit_prior_m7 <- stan(
  file = "stan_programs/model7_prior.stan",
  data = stan_data_m7_prior,
  algorithm = "Fixed_param",
  iter = 1000,
  chains = 1,
  seed = 1234
)

samples_prior_m7 <- util$extract_expectand_vals(fit_prior_m7)
```

### Prior on sigma_mu (developer mean spread)

```{r}
#| label: fig-m7-prior-sigma-mu
#| fig-cap: "Model 7 prior: sigma_mu (developer mean spread)"

util$plot_line_hist(samples_prior_m7$sigma_mu, 0, 2.5, 0.05,
                    xlab = "sigma_mu")
```

### Prior on sigma_delta (task deviation spread)

```{r}
#| label: fig-m7-prior-sigma-delta
#| fig-cap: "Model 7 prior: sigma_delta (task deviation spread)"

util$plot_line_hist(samples_prior_m7$sigma_delta, 0, 1.5, 0.05,
                    xlab = "sigma_delta")
```

### Prior on lambda_e (delta -\> exposure)

```{r}
#| label: fig-m7-prior-lambda-e
#| fig-cap: "Model 7 prior: lambda_e (delta effect on exposure)"

util$plot_line_hist(samples_prior_m7$lambda_e, 0, 3, 0.1,
                    xlab = "lambda_e")
```

### Prior on lambda_r (delta -\> resources)

```{r}
#| label: fig-m7-prior-lambda-r
#| fig-cap: "Model 7 prior: lambda_r (delta effect on resources)"

util$plot_line_hist(samples_prior_m7$lambda_r, 0, 3, 0.1,
                    xlab = "lambda_r")
```

### Prior on beta_eta (eta -\> completion)

```{r}
#| label: fig-m7-prior-beta-eta
#| fig-cap: "Model 7 prior: beta_eta (eta effect on completion)"

util$plot_line_hist(samples_prior_m7$beta_eta, 0, 2.5, 0.05,
                    xlab = "beta_eta")
```

### Prior on beta_eta_trt (eta x treatment interaction)

```{r}
#| label: fig-m7-prior-beta-eta-trt
#| fig-cap: "Model 7 prior: beta_eta_trt (heterogeneous treatment effect)"

util$plot_line_hist(samples_prior_m7$beta_eta_trt, -0.6, 0.6, 0.025,
                    xlab = "beta_eta_trt")
abline(v = 0, lty = 2, lwd = 2)
```

### Prior predictive: simulated eta distribution

```{r}
#| label: fig-m7-prior-eta
#| fig-cap: "Model 7 prior predictive: eta distribution"

util$plot_hist_quantiles(samples_prior_m7, 'eta', -4, 4, 0.25,
                         xlab = "eta")
```

### Prior predictive: simulated delta distribution

```{r}
#| label: fig-m7-prior-delta
#| fig-cap: "Model 7 prior predictive: delta distribution"

util$plot_hist_quantiles(samples_prior_m7, 'delta', -3, 3, 0.2,
                         xlab = "delta")
```

### Prior predictive: simulated exposure distribution

```{r}
#| label: fig-m7-prior-exposure
#| fig-cap: "Model 7 prior predictive: exposure distribution"

util$plot_hist_quantiles(samples_prior_m7, 'exposure_sim', 0.5, 5.5, 1,
                         xlab = "Exposure (1-5)")
```

### Prior predictive: simulated resources distribution

```{r}
#| label: fig-m7-prior-resources
#| fig-cap: "Model 7 prior predictive: resources distribution"

util$plot_hist_quantiles(samples_prior_m7, 'resources_sim', 0.5, 3.5, 1,
                         xlab = "Resources (1-3)")
```

### Prior predictive: simulated completion time

```{r}
#| label: fig-m7-prior-y
#| fig-cap: "Model 7 prior predictive: completion time distribution"

util$plot_hist_quantiles(samples_prior_m7, 'y_sim', 0, 800, 25,
                         xlab = "Completion time (minutes)")
```

### Prior predictive: treatment effect

```{r}
#| label: fig-m7-prior-pct-lift
#| fig-cap: "Model 7 prior: treatment effect at eta = 0"

util$plot_line_hist(samples_prior_m7$pct_lift, -100, 100, 5,
                    xlab = "% change in completion time")
abline(v = 0, lty = 2, lwd = 2)
```

### Prior predictive summary

```{r}
#| label: m7-prior-summary

cat("Prior predictive summary (Model 7):\n\n")

cat("sigma_mu (developer mean spread):\n")
print(util$my_q(samples_prior_m7$sigma_mu))

cat("\nsigma_delta (task deviation spread):\n")
print(util$my_q(samples_prior_m7$sigma_delta))

cat("\nlambda_e (delta -> exposure):\n")
print(util$my_q(samples_prior_m7$lambda_e))

cat("\nlambda_r (delta -> resources):\n")
print(util$my_q(samples_prior_m7$lambda_r))

cat("\nbeta_eta (eta -> completion):\n")
print(util$my_q(samples_prior_m7$beta_eta))

cat("\nbeta_eta_trt (eta x treatment):\n")
print(util$my_q(samples_prior_m7$beta_eta_trt))

cat("\npct_lift (treatment effect at eta=0):\n")
print(util$my_q(samples_prior_m7$pct_lift))

cat("\nMean eta by draw:\n")
print(util$my_q(samples_prior_m7$mean_eta))

cat("\nSD eta by draw:\n")
print(util$my_q(samples_prior_m7$sd_eta))

cat("\nMean exposure by draw:\n")
print(util$my_q(samples_prior_m7$mean_exposure))

cat("\nMean resources by draw:\n")
print(util$my_q(samples_prior_m7$mean_resources))
```

## Fit Model 7

```{r}
#| label: m7-data

stan_data_m7 <- list(
  N = stan_data_m6$N,
  J = stan_data_m6$J,
  dev_idx = stan_data_m6$dev_idx,
  y = stan_data_m6$y,
  forecast = stan_data_m6$forecast,
  ai_access = stan_data_m6$ai_access,

  N_obs_exposure = stan_data_m6$N_obs_exposure,
  exposure_idx = stan_data_m6$exposure_idx,
  exposure = stan_data_m6$exposure,

  N_obs_resources = stan_data_m6$N_obs_resources,
  resources_idx = stan_data_m6$resources_idx,
  resources = stan_data_m6$resources,

  # Dirichlet hyperparameters
  rho_e = rep(1/5, 5),
  tau_e = 0.1,
  rho_r = rep(1/3, 3),
  tau_r = 0.2
)
```

```{r}
#| label: m7-fit

fit_m7 <- stan(
  file = "stan_programs/model7.stan",
  data = stan_data_m7,
  iter = 2000,
  warmup = 1000,
  chains = 4,
  seed = 1234,
  control = list(adapt_delta = 0.8)
)

samples_m7 <- util$extract_expectand_vals(fit_m7)
diagnostics_m7 <- util$extract_hmc_diagnostics(fit_m7)
```

## Diagnostics

```{r}
#| label: m7-diagnostics

util$check_all_hmc_diagnostics(diagnostics_m7)

# Exclude integer prediction arrays from expectand diagnostics
# (tail_hat doesn't work well with discrete values)
exclude_patterns <- c("exposure_pred", "resources_pred", "forecast_shifted_pred")
samples_m7_continuous <- samples_m7[!grepl(paste(exclude_patterns, collapse = "|"), names(samples_m7))]
util$check_all_expectand_diagnostics(samples_m7_continuous)
```

## Posterior Retrodictive Checks

### Completion time

```{r}
#| label: fig-m7-retro-y
#| fig-cap: "Model 7 posterior retrodictive: completion time"

util$plot_hist_quantiles(samples_m7, 'y_pred', 0, 800, 25,
                         baseline_values = stan_data_m7$y,
                         xlab = "Completion time (minutes)")
```

```{r}
#| label: fig-m7-retro-log-y
#| fig-cap: "Model 7 posterior retrodictive: log completion time"

util$plot_hist_quantiles(samples_m7, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m7$y),
                         xlab = "Log completion time")
```

### Forecast

```{r}
#| label: fig-m7-retro-forecast
#| fig-cap: "Model 7 posterior retrodictive: forecast"

util$plot_hist_quantiles(samples_m7, 'forecast_pred', 0, 400, 25,
                         baseline_values = stan_data_m7$forecast,
                         xlab = "Forecast (minutes)")
```

### Exposure

```{r}
#| label: fig-m7-retro-exposure
#| fig-cap: "Model 7 posterior retrodictive: exposure distribution (observed cases)"

exposure_pred_obs_m7 <- samples_m7[paste0('exposure_pred[', stan_data_m7$exposure_idx, ']')]
names(exposure_pred_obs_m7) <- paste0('exposure_pred_obs[', seq_along(stan_data_m7$exposure_idx), ']')

util$plot_hist_quantiles(exposure_pred_obs_m7, 'exposure_pred_obs', 0.5, 5.5, 1,
                         baseline_values = stan_data_m7$exposure,
                         xlab = "Exposure (1-5)")
```

### Resources

```{r}
#| label: fig-m7-retro-resources
#| fig-cap: "Model 7 posterior retrodictive: resources distribution (observed cases)"

resources_pred_obs_m7 <- samples_m7[paste0('resources_pred[', stan_data_m7$resources_idx, ']')]
names(resources_pred_obs_m7) <- paste0('resources_pred_obs[', seq_along(stan_data_m7$resources_idx), ']')

util$plot_hist_quantiles(resources_pred_obs_m7, 'resources_pred_obs', 0.5, 3.5, 1,
                         baseline_values = stan_data_m7$resources,
                         xlab = "Resources (1-3)")
```

## Parameter Posteriors

### Treatment effect at eta = 0

```{r}
#| label: fig-m7-pct-lift
#| fig-cap: "Model 7: treatment effect at eta = 0"

util$plot_line_hist(samples_m7$pct_lift, -60, 60, 2.5,
                    xlab = "% change in completion time")
abline(v = 0, lty = 2, lwd = 2)

cat("Treatment effect at eta = 0:\n")
print(util$my_q(samples_m7$pct_lift))
```

### Heterogeneous treatment effect (beta_eta_trt)

```{r}
#| label: fig-m7-beta-eta-trt
#| fig-cap: "Model 7: beta_eta_trt (heterogeneous treatment effect)"

util$plot_line_hist(samples_m7$beta_eta_trt, -0.5, 0.5, 0.025,
                    xlab = "beta_eta_trt")
abline(v = 0, lty = 2, lwd = 2)

cat("beta_eta_trt:\n")
print(util$my_q(samples_m7$beta_eta_trt))
```

### Treatment effect by eta level

```{r}
#| label: fig-m7-trt-by-eta
#| fig-cap: "Model 7: treatment effect at different eta levels"

par(mfrow = c(1, 1))

util$plot_line_hist(samples_m7$pct_lift_low_eta, -80, 80, 4,
                    xlab = "% lift")
abline(v = 0, lty = 2, lwd = 2)
title("Low eta (easy)", line = 1)

util$plot_line_hist(samples_m7$pct_lift, -80, 80, 4,
                    xlab = "% lift")
abline(v = 0, lty = 2, lwd = 2)
title("eta = 0 (average)", line = 1)

util$plot_line_hist(samples_m7$pct_lift_high_eta, -80, 80, 4,
                    xlab = "% lift")
abline(v = 0, lty = 2, lwd = 2)
title("High eta (hard)", line = 1)
```

### lambda_e (delta -\> exposure)

```{r}
#| label: fig-m7-lambda-e
#| fig-cap: "Model 7: lambda_e posterior"

util$plot_line_hist(samples_m7$lambda_e, 0, 3, 0.1,
                    xlab = "lambda_e")

cat("lambda_e (delta -> exposure):\n")
print(util$my_q(samples_m7$lambda_e))
```

### lambda_r (delta -\> resources)

```{r}
#| label: fig-m7-lambda-r
#| fig-cap: "Model 7: lambda_r posterior"

util$plot_line_hist(samples_m7$lambda_r, -3, 3, 0.1,
                    xlab = "lambda_r")

cat("lambda_r (delta -> resources):\n")
print(util$my_q(samples_m7$lambda_r))
```

### sigma_mu (developer mean spread)

```{r}
#| label: fig-m7-sigma-mu
#| fig-cap: "Model 7: sigma_mu posterior"

util$plot_line_hist(samples_m7$sigma_mu, 0, 1.5, 0.05,
                    xlab = "sigma_mu")

cat("sigma_mu:\n")
print(util$my_q(samples_m7$sigma_mu))
```

### sigma_delta (task deviation spread)

```{r}
#| label: fig-m7-sigma-delta
#| fig-cap: "Model 7: sigma_delta posterior"

util$plot_line_hist(samples_m7$sigma_delta, 0, 1, 0.025,
                    xlab = "sigma_delta")

cat("sigma_delta:\n")
print(util$my_q(samples_m7$sigma_delta))
```

### beta_eta (eta -\> completion)

```{r}
#| label: fig-m7-beta-eta
#| fig-cap: "Model 7: beta_eta posterior"

util$plot_line_hist(samples_m7$beta_eta, 0, 2, 0.05,
                    xlab = "beta_eta")

cat("beta_eta:\n")
print(util$my_q(samples_m7$beta_eta))
```

## Prior vs Posterior Comparisons

```{r}
#| label: fig-m7-prior-post-sigma-mu
#| fig-cap: "Model 7: Prior (teal) vs Posterior for sigma_mu"

util$plot_expectand_pushforward(samples_m7[["sigma_mu"]], 25,
                                display_name = "sigma_mu", flim = c(0, 1.5))
xs <- seq(0, 1.5, 0.01)
lines(xs, 2 * dnorm(xs, 0, 0.78), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-sigma-delta
#| fig-cap: "Model 7: Prior (teal) vs Posterior for sigma_delta"

util$plot_expectand_pushforward(samples_m7[["sigma_delta"]], 25,
                                display_name = "sigma_delta", flim = c(0, 1))
xs <- seq(0, 1, 0.01)
lines(xs, 2 * dnorm(xs, 0, 0.39), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-sigma-t
#| fig-cap: "Model 7: Prior (teal) vs Posterior for sigma_t"

util$plot_expectand_pushforward(samples_m7[["sigma_t"]], 25,
                                display_name = "sigma_t", flim = c(0, 0.8))
xs <- seq(0, 0.8, 0.01)
lines(xs, 2 * dnorm(xs, 0, 0.25), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-kappa
#| fig-cap: "Model 7: Prior (teal) vs Posterior for kappa"

util$plot_expectand_pushforward(samples_m7[["kappa"]], 25,
                                display_name = "kappa", flim = c(0, 0.5))
xs <- seq(0, 0.5, 0.005)
lines(xs, 2 * dnorm(xs, 0, 0.10), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-alpha-f
#| fig-cap: "Model 7: Prior (teal) vs Posterior for alpha_f"

util$plot_expectand_pushforward(samples_m7[["alpha_f"]], 25,
                                display_name = "alpha_f", flim = c(1.5, 4.5))
xs <- seq(1.5, 4.5, 0.01)
lines(xs, dnorm(xs, log(17), 0.30), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-alpha-t
#| fig-cap: "Model 7: Prior (teal) vs Posterior for alpha_t"

util$plot_expectand_pushforward(samples_m7[["alpha_t"]], 25,
                                display_name = "alpha_t", flim = c(3.5, 5.5))
xs <- seq(3.5, 5.5, 0.01)
lines(xs, dnorm(xs, log(90), 0.40), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-beta-eta
#| fig-cap: "Model 7: Prior (teal) vs Posterior for beta_eta"

util$plot_expectand_pushforward(samples_m7[["beta_eta"]], 25,
                                display_name = "beta_eta", flim = c(0, 2.5))
xs <- seq(0, 2.5, 0.01)
lines(xs, dnorm(xs, 1, 0.3), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-beta-trt
#| fig-cap: "Model 7: Prior (teal) vs Posterior for beta_trt"

util$plot_expectand_pushforward(samples_m7[["beta_trt"]], 25,
                                display_name = "beta_trt", flim = c(-2, 2))
xs <- seq(-2, 2, 0.01)
lines(xs, dnorm(xs, 0, 0.7), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-beta-eta-trt
#| fig-cap: "Model 7: Prior (teal) vs Posterior for beta_eta_trt"

util$plot_expectand_pushforward(samples_m7[["beta_eta_trt"]], 25,
                                display_name = "beta_eta_trt", flim = c(-0.5, 0.5))
xs <- seq(-0.5, 0.5, 0.01)
lines(xs, dnorm(xs, 0, 0.15), lwd = 2, col = c_light_teal)
abline(v = 0, lty = 2)
```

```{r}
#| label: fig-m7-prior-post-lambda-e
#| fig-cap: "Model 7: Prior (teal) vs Posterior for lambda_e"

util$plot_expectand_pushforward(samples_m7[["lambda_e"]], 25,
                                display_name = "lambda_e", flim = c(-1, 3))
xs <- seq(-1, 3, 0.01)
lines(xs, dnorm(xs, 1, 0.43), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-lambda-r
#| fig-cap: "Model 7: Prior (teal) vs Posterior for lambda_r"

util$plot_expectand_pushforward(samples_m7[["lambda_r"]], 25,
                                display_name = "lambda_r", flim = c(-1, 3))
xs <- seq(-1, 3, 0.01)
lines(xs, dnorm(xs, 1, 0.43), lwd = 2, col = c_light_teal)
```

```{r}
#| label: fig-m7-prior-post-latent
#| fig-cap: "Model 7: Prior (teal) vs Posterior for example latent variables"

par(mfrow = c(1, 2))

# mu[1] - example developer mean
util$plot_expectand_pushforward(samples_m7[["mu[1]"]], 25,
                                display_name = "mu[1]", flim = c(-2, 2))
xs <- seq(-2, 2, 0.01)
lines(xs, dnorm(xs, 0, 0.78), lwd = 2, col = c_light_teal)

# delta[1] - example task deviation
util$plot_expectand_pushforward(samples_m7[["delta[1]"]], 25,
                                display_name = "delta[1]", flim = c(-1.5, 1.5))
xs <- seq(-1.5, 1.5, 0.01)
lines(xs, dnorm(xs, 0, 0.39), lwd = 2, col = c_light_teal)
```

### Posterior summaries for all eta values

```{r}
#| label: fig-m7-eta-summary
#| fig-cap: "Model 7: Posterior mean and 80% intervals for all eta values"
#| fig-height: 6

# Extract eta samples
eta_names <- paste0("eta[", 1:stan_data_m7$N, "]")
eta_samples <- samples_m7[eta_names]

# Compute posterior summaries
eta_mean <- sapply(eta_samples, mean)
eta_q10 <- sapply(eta_samples, quantile, probs = 0.10)
eta_q90 <- sapply(eta_samples, quantile, probs = 0.90)

# Sort by posterior mean for visualization
ord <- order(eta_mean)

# Plot
plot(1:stan_data_m7$N, eta_mean[ord], pch = 19, cex = 0.5,
     xlab = "Observation (sorted by posterior mean)",
     ylab = "eta",
     ylim = range(c(eta_q10, eta_q90)),
     main = "Posterior eta: mean and 80% intervals")
segments(1:stan_data_m7$N, eta_q10[ord], 1:stan_data_m7$N, eta_q90[ord],
         col = rgb(0, 0, 0, 0.3))
abline(h = 0, lty = 2, col = "red")

cat("eta posterior summary:\n")
cat("  Mean of means:", round(mean(eta_mean), 3), "\n")
cat("  SD of means:", round(sd(eta_mean), 3), "\n")
cat("  Range of means:", round(range(eta_mean), 3), "\n")
```

```{r}
#| label: fig-m7-mu-summary
#| fig-cap: "Model 7: Posterior mean and 80% intervals for developer-level mu"
#| fig-height: 6

# Extract mu samples
mu_names <- paste0("mu[", 1:stan_data_m7$J, "]")
mu_samples <- samples_m7[mu_names]

# Compute posterior summaries
mu_mean <- sapply(mu_samples, mean)
mu_q10 <- sapply(mu_samples, quantile, probs = 0.10)
mu_q90 <- sapply(mu_samples, quantile, probs = 0.90)

# Sort by posterior mean for visualization
ord_dev <- order(mu_mean)

# Plot
plot(1:stan_data_m7$J, mu_mean[ord_dev], pch = 19, cex = 0.8,
     xlab = "Developer (sorted by posterior mean)",
     ylab = "mu",
     ylim = range(c(mu_q10, mu_q90)),
     main = "Posterior mu: mean and 80% intervals")
segments(1:stan_data_m7$J, mu_q10[ord_dev], 1:stan_data_m7$J, mu_q90[ord_dev],
         col = rgb(0, 0, 0, 0.5), lwd = 2)
abline(h = 0, lty = 2, col = "red")

cat("mu posterior summary:\n")
cat("  Mean of means:", round(mean(mu_mean), 3), "\n")
cat("  SD of means:", round(sd(mu_mean), 3), "\n")
cat("  Range of means:", round(range(mu_mean), 3), "\n")
```

## Compare Models 6 and 7

```{r}
#| label: fig-m6-m7-compare-trt
#| fig-cap: "Treatment effect comparison: Model 6 vs Model 7 (at eta/gap = 0)"

util$plot_line_hist(samples_m6$pct_lift, -60, 60, 2.5,
                    xlab = "% change in completion time",
                    col = "purple")
util$plot_line_hist(samples_m7$pct_lift, -60, 60, 2.5,
                    col = "darkgreen", add = TRUE)
abline(v = 0, lty = 2, lwd = 2)
legend("topright", c("Model 6", "Model 7"),
       fill = c("purple", "darkgreen"))
```

```{r}
#| label: fig-m6-m7-compare-log-y
#| fig-cap: "Log completion time posterior predictive: Model 6 (top) vs Model 7 (bottom)"
#| fig-height: 8

par(mfrow = c(2, 1))

util$plot_hist_quantiles(samples_m6, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m6$y),
                         xlab = "log(completion time)")
title("Model 6", line = 1)

util$plot_hist_quantiles(samples_m7, 'log_y_pred', 2, 8, 0.25,
                         baseline_values = log(stan_data_m7$y),
                         xlab = "log(completion time)")
title("Model 7", line = 1)
```

## Model 7 Summary

```{r}
#| label: m7-summary

cat("=== MODEL 7 POSTERIOR SUMMARY ===\n\n")

cat("LATENT STRUCTURE:\n")
cat("  sigma_mu (developer mean spread):\n")
print(util$my_q(samples_m7$sigma_mu))
cat("  sigma_delta (task deviation spread):\n")
print(util$my_q(samples_m7$sigma_delta))

cat("\nORDINAL LOADINGS:\n")
cat("  lambda_e (delta -> exposure, negative in model):\n")
print(util$my_q(samples_m7$lambda_e))
cat("  lambda_r (delta -> resources, positive in model):\n")
print(util$my_q(samples_m7$lambda_r))

cat("\nCOMPLETION TIME MODEL:\n")
cat("  beta_eta (eta -> log completion):\n")
print(util$my_q(samples_m7$beta_eta))
cat("  beta_trt (treatment at eta=0):\n")
print(util$my_q(samples_m7$beta_trt))
cat("  beta_eta_trt (eta x treatment):\n")
print(util$my_q(samples_m7$beta_eta_trt))

cat("\nTREATMENT EFFECTS:\n")
cat("  At eta = -1 (easy):\n")
print(util$my_q(samples_m7$pct_lift_low_eta))
cat("  At eta = 0 (average):\n")
print(util$my_q(samples_m7$pct_lift))
cat("  At eta = +1 (hard):\n")
print(util$my_q(samples_m7$pct_lift_high_eta))
```
